{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Safa06/Thesis/blob/main/channel_att_IP_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLfcv6eW4iAw"
      },
      "outputs": [],
      "source": [
        "# VGG16\n",
        "#import cv2\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy.io\n",
        "from scipy.io import loadmat\n",
        "#from skimage.transform import resize\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdFiapty4nEs",
        "outputId": "8acff7b7-8816-473e-b509-3990e2ba4306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(145, 145, 200)\n",
            "(145, 145)\n"
          ]
        }
      ],
      "source": [
        "mat_data1= scipy.io.loadmat('Indian_pines_corrected.mat')\n",
        "mat_data2=scipy.io.loadmat('Indian_pines_gt.mat')\n",
        "X=mat_data1['indian_pines_corrected']\n",
        "y=mat_data2['indian_pines_gt']\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okW4hQ464nBI",
        "outputId": "a33a6a52-0430-44de-de37-2869bf184b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(145, 145, 16) (145, 145)\n"
          ]
        }
      ],
      "source": [
        "# Apply PCA to minimize band from 200 to 3 band\n",
        "def applyPCA(X, numComponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    return newX, pca\n",
        "\n",
        "K = 16\n",
        "X,pca= applyPCA(X,numComponents=K)\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "\n",
        "\n",
        "#padding with zero\n",
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxOM1Tt84m_B"
      },
      "outputs": [],
      "source": [
        "# Window for patches\n",
        "windowSize=11\n",
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels\n",
        "\n",
        "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
        "#print(X.shape,y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmyVpGrP4m8v",
        "outputId": "ec1cb447-495d-4ff7-cb96-69daf3724654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3074, 11, 11, 16) (7175, 11, 11, 16) (3074,) (7175,)\n"
          ]
        }
      ],
      "source": [
        "#Split train-test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.7, random_state=42)\n",
        "\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taEDNbrQ4-Gs"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# def channel_attention_module(inputs, reduction_ratio=16):\n",
        "#   \"\"\"Implements a channel attention module.\n",
        "\n",
        "#   Args:\n",
        "#       inputs: The input tensor of shape (batch_size, height, width, channels).\n",
        "#       reduction_ratio: The reduction ratio for channel squeezing. Defaults to 16.\n",
        "\n",
        "#   Returns:\n",
        "#       A tensor with the same shape as the input, containing the channel-wise attention weights.\n",
        "#   \"\"\"\n",
        "\n",
        "#   avg_pool = layers.GlobalAveragePooling2D()(inputs)  # Average pool across spatial dimensions\n",
        "#   max_pool = layers.GlobalMaxPooling2D()(inputs)  # Max pool across spatial dimensions\n",
        "\n",
        "#   shared_conv = layers.Conv1D(inputs.shape[-1] // reduction_ratio, kernel_size=1, activation='relu')(\n",
        "#       keras.layers.concatenate([avg_pool, max_pool]))  # Concatenate and reduce dimensionality\n",
        "\n",
        "#   shared_conv = layers.Conv1D(inputs.shape[-1], kernel_size=1, activation='sigmoid')(shared_conv)  # Project back to channel dimension and apply sigmoid\n",
        "\n",
        "#   return inputs * shared_conv  # Multiply input by channel-wise attention weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9HHwspw4m6g"
      },
      "outputs": [],
      "source": [
        "# input_shape = (11,11,16)\n",
        "# S = windowSize\n",
        "# inputs = keras.Input(shape=input_shape)\n",
        "# L = K\n",
        "# #output_units = 9 if (dataset == 'PU' or dataset == 'PC') else 16\n",
        "\n",
        "# ## input layer\n",
        "# #input_shape=(11,11,16)\n",
        "\n",
        "# #for 3D CNN--input_layer=Input(S, S, L, 1)\n",
        "\n",
        "# #Model\n",
        "# # model = Sequential()\n",
        "\n",
        "# # #Block 1\n",
        "\n",
        "# # x=model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding=\"same\")(inputs))\n",
        "# # x=model.add(Conv2D(64, kernel_size=(3,3), activation='relu',padding=\"same\"))(x)\n",
        "# # x=model.add(MaxPooling2D((2, 2), strides=(2, 2)))(x)\n",
        "# # x=channel_attention_module(x);\n",
        "\n",
        "# # # Block 2\n",
        "# # x=model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(MaxPooling2D((2, 2), strides=(2, 2)))(x)\n",
        "# # x=channel_attention_module(x);\n",
        "\n",
        "# # # Block 3\n",
        "# # x=model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(MaxPooling2D((2, 2), strides=(2, 2)))(x)\n",
        "# # x=channel_attention_module(x);\n",
        "\n",
        "# # # Block 4\n",
        "# # x=model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # # model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "# # x=model.add(MaxPooling2D((1, 1), strides=(1, 1)))(x)\n",
        "# # x=channel_attention_module(x);\n",
        "\n",
        "\n",
        "# # # Block 5\n",
        "# # x=model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # x=model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))(x)\n",
        "# # #model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "# # x=model.add(MaxPooling2D((1, 1), strides=(1, 1)))(x)\n",
        "# # x=channel_attention_module(x);\n",
        "\n",
        "# # # Fully connected layers\n",
        "# # x=model.add(Flatten())(x)\n",
        "# # x=model.add(Dense(units=4096, activation='relu'))\n",
        "# # x=model.add(Dense(units=4096, activation='relu'))\n",
        "# # x=model.add(Dense(units=16, activation='softmax'))\n",
        "\n",
        "# # model.build()\n",
        "# # model.summary()\n",
        "\n",
        "\n",
        "# # model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "# def channel_attention_module(inputs, reduction_ratio=16):\n",
        "#   \"\"\"Implements a channel attention module.\n",
        "\n",
        "#   Args:\n",
        "#       inputs: The input tensor of shape (batch_size, height, width, channels).\n",
        "#       reduction_ratio: The reduction ratio for channel squeezing. Defaults to 16.\n",
        "\n",
        "#   Returns:\n",
        "#       A tensor with the same shape as the input, containing the channel-wise attention weights.\n",
        "#   \"\"\"\n",
        "\n",
        "#   avg_pool = layers.Reshape((1, inputs.shape[-1]))(layers.GlobalAveragePooling2D()(inputs)) # Average pool across spatial dimensions\n",
        "#   max_pool = layers.Reshape((1, inputs.shape[-1]))(layers.GlobalMaxPooling2D()(inputs))  # Max pool across spatial dimensions\n",
        "\n",
        "#   shared_conv = layers.Conv1D(inputs.shape[-1] // reduction_ratio, kernel_size=1, activation='relu')(\n",
        "#       keras.layers.concatenate([avg_pool, max_pool]))  # Concatenate and reduce dimensionality\n",
        "\n",
        "#   shared_conv = layers.Conv1D(inputs.shape[-1], kernel_size=1, activation='sigmoid')(shared_conv)  # Project back to channel dimension and apply sigmoid\n",
        "\n",
        "#   return inputs * shared_conv  # Multiply input by channel-wise attention weights\n",
        "\n",
        "\n",
        "# # def channel_attention_module(inputs, reduction_ratio=16):\n",
        "# #   \"\"\"Implements a channel attention module.\n",
        "\n",
        "# #   Args:\n",
        "# #       inputs: The input tensor of shape (batch_size, height, width, channels).\n",
        "# #       reduction_ratio: The reduction ratio for channel squeezing. Defaults to 16.\n",
        "\n",
        "# #   Returns:\n",
        "# #       A tensor with the same shape as the input, containing the channel-wise attention weights.\n",
        "# #   \"\"\"\n",
        "\n",
        "# #   avg_pool = layers.GlobalAveragePooling2D()(inputs)  # Average pool across spatial dimensions\n",
        "# #   max_pool = layers.GlobalMaxPooling2D()(inputs)  # Max pool across spatial dimensions\n",
        "\n",
        "# #   shared_conv = layers.Conv1D(inputs.shape[-1]\n",
        "# #                   // reduction_ratio, kernel_size=1, activation='relu')(\n",
        "# #       keras.layers.concatenate([avg_pool, max_pool]))  # Concatenate and reduce dimensionality\n",
        "\n",
        "# #   shared_conv = layers.Conv1D(inputs.shape[-1], kernel_size=1, activation='sigmoid')(shared_conv)  # Project back to channel dimension and apply sigmoid\n",
        "\n",
        "# #   return inputs * shared_conv  # Multiply input by channel-wise attention weights\n",
        "\n",
        "# # def vgg16_with_channel_attention(input_shape, num_classes):\n",
        "# #   \"\"\"Creates a scratch VGG16 model with channel attention in convolutional blocks.\n",
        "\n",
        "# #   Args:\n",
        "# #       input_shape: The input shape of the model (height, width, channels).\n",
        "# #       num_classes: The number of classes in the HSI classification task.\n",
        "\n",
        "# #   Returns:\n",
        "# #       A compiled Keras model ready for training.\n",
        "# #   \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#   # Block 1\n",
        "# x = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "# x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "# x = channel_attention_module(x)  # Add channel attention after block 1\n",
        "\n",
        "# # Block 2\n",
        "# x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "# x = channel_attention_module(x)  # Add channel attention after block 2\n",
        "\n",
        "# # Block 3\n",
        "# x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "# #x = channel_attention_module(x)  # Add channel attention after block 3\n",
        "\n",
        "# # Block 4\n",
        "# x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.MaxPooling2D((1, 1), strides=(1, 1))(x)\n",
        "# #x = channel_attention_module(x)  # Add channel attention after block 4\n",
        "\n",
        "# # Block 5\n",
        "# x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "# x = layers.MaxPooling2D((1, 1), strides=(1, 1))(x)\n",
        "# #x = channel_attention_module(x)\n",
        "\n",
        "#  # Fully connected layers\n",
        "# # x=model.add(Flatten())(x)\n",
        "# # x=model.add(Dense(units=4096, activation='relu'))\n",
        "# # x=model.add(Dense(units=4096, activation='relu'))\n",
        "# # x=model.add(Dense(units=16, activation='softmax'))\n",
        "\n",
        "\n",
        "# # Fully-connected layers for classification\n",
        "# x = layers.Flatten()(x)\n",
        "# x = layers.Dense(4096, activation='relu')(x)  # Example: First dense layer with 4096 units and ReLU activation\n",
        "# #x = layers.Dropout(0.5)(x)  # Example: Dropout for regularization\n",
        "# x = layers.Dense(4096, activation='relu')(x)  # Example: Second dense layer with 4096 units and ReLU activation\n",
        "# #x = layers.Dropout(0.5)(x)  # Example: Dropout for regularization\n",
        "# outputs = layers.Dense(16, activation='softmax')(x)  # Final output layer with softmax activation\n",
        "\n",
        "\n",
        "# model = create_vgg16_ca(input_shape, num_classes)\n",
        "# model.summary()\n",
        "\n",
        "# model.build(input_shape=input_shape)\n",
        "\n",
        "\n",
        "\n",
        "# # Compile the model\n",
        "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNXE5EF0gKdJ",
        "outputId": "0e9f846e-82ef-463f-f9de-100fe946880b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.11.0 in /usr/local/lib/python3.10/dist-packages (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (24.3.7)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.62.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.9.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (24.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.36.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQLvwOhxbvbM",
        "outputId": "478ef410-0af2-4c89-83e6-ee4ea7a03e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f96_rCE6aX57",
        "outputId": "e7316051-345d-41e0-d9aa-959d17665e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 11, 11, 16)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 11, 11, 64)        9280      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 5, 5, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " channel_attention (ChannelA  (None, 5, 5, 64)         64        \n",
            " ttention)                                                       \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 5, 5, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 5, 5, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 2, 2, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 1, 1, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 1, 1, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 1, 1, 512)         2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              2101248   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                65552     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,670,352\n",
            "Trainable params: 33,670,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# def channel_attention_module(inputs, reduction_ratio=16):\n",
        "#   \"\"\"Implements a channel attention module.\n",
        "\n",
        "#   Args:\n",
        "#       inputs: The input tensor of shape (batch_size, height, width, channels).\n",
        "#       reduction_ratio: The reduction ratio for channel squeezing. Defaults to 16.\n",
        "\n",
        "#   Returns:\n",
        "#       A tensor with the same shape as the input, containing the channel-wise attention weights.\n",
        "#   \"\"\"\n",
        "\n",
        "#   avg_pool = layers.GlobalAveragePooling2D()(inputs)  # Average pool across spatial dimensions\n",
        "#   max_pool = layers.GlobalMaxPooling2D()(inputs)  # Max pool across spatial dimensions\n",
        "\n",
        "# # Reshape the pooling outputs to have three dimensions\n",
        "#   # avg_pool = layers.Reshape((1, 1, avg_pool.shape[-1]))\n",
        "#   # max_pool = layers.Reshape((1, 1, max_pool.shape[-1]))\n",
        "\n",
        "#   # Reshape the pooling outputs to have three dimensions\n",
        "#   avg_pool = layers.Reshape((1, 1, avg_pool.shape[-1]))(avg_pool)\n",
        "#   max_pool = layers.Reshape((1, 1, max_pool.shape[-1]))(max_pool)\n",
        "\n",
        "#   # Print the shapes of reshaped tensors for debugging\n",
        "#   print(\"Avg Pool Shape:\", avg_pool.shape)\n",
        "#   print(\"Max Pool Shape:\", max_pool.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   shared_conv = layers.Conv1D(inputs.shape[-1] // reduction_ratio, kernel_size=1, activation='relu')(\n",
        "#       keras.layers.concatenate([avg_pool, max_pool]))  # Concatenate and reduce dimensionality\n",
        "\n",
        "#   shared_conv = layers.Conv1D(inputs.shape[-1], kernel_size=1, activation='sigmoid')(shared_conv)  # Project back to channel dimension and apply sigmoid\n",
        "\n",
        "#   return inputs * shared_conv  # Multiply input by channel-wise attention weights\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, GlobalAveragePooling2D, Multiply\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "class ChannelAttention(Layer):\n",
        "    def __init__(self):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        channels = input_shape[-1]\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.scale = self.add_weight(\"scale\", shape=[channels,], initializer=tf.keras.initializers.Ones(), trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.avg_pool(inputs)\n",
        "        x = tf.expand_dims(tf.expand_dims(x, axis=1), axis=1)  # Add dimensions for broadcasting\n",
        "        x = tf.math.multiply(x, self.scale)\n",
        "        return Multiply()([inputs, x])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def vgg16_with_channel_attention(input_shape, num_classes):\n",
        "  \"\"\"Creates a scratch VGG16 model with channel attention in convolutional blocks.\n",
        "\n",
        "  Args:\n",
        "      input_shape: The input shape of the model (height, width, channels).\n",
        "      num_classes: The number of classes in the HSI classification task.\n",
        "\n",
        "  Returns:\n",
        "      A compiled Keras model ready for training.\n",
        "  \"\"\"\n",
        "\n",
        "  inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "  # Block 1\n",
        "  x = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "  x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "  #x = channel_attention_module(x)\n",
        "  x=ChannelAttention()(x)  # Add channel attention after block 1\n",
        "\n",
        "  # Block 2\n",
        "  x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "  #x = channel_attention_module(x)\n",
        "  #x=ChannelAttention()(x)  # Add channel attention after block 2\n",
        "\n",
        "  # Block 3\n",
        "  x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "  #x = channel_attention_module(x)\n",
        "  #x=ChannelAttention()(x)  # Add channel attention after block 3\n",
        "\n",
        "  # Block 4\n",
        "  x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D((1, 1), strides=(1, 1))(x)\n",
        "  #x = channel_attention_module(x)\n",
        "  #x=ChannelAttention()(x)  # Add channel attention after block 4\n",
        "\n",
        "  # Block 5\n",
        "  x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.MaxPooling2D((1, 1), strides=(1, 1))(x)\n",
        "  #x = channel_attention_module(x)\n",
        "  #x=ChannelAttention()(x)  # Add channel attention after block\n",
        "\n",
        "\n",
        "  # Flatten the output from the final convolutional layer\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  # Fully-connected layers for classification\n",
        "  x = layers.Dense(4096, activation='relu')(x)  # Example: First dense layer with 4096 units and ReLU activation\n",
        "  #x = layers.Dropout(0.5)(x)  # Example: Dropout for regularization\n",
        "  x = layers.Dense(4096, activation='relu')(x)  # Example: Second dense layer with 4096 units and ReLU activation\n",
        "  #x = layers.Dropout(0.5)(x)  # Example: Dropout for regularization\n",
        "  outputs = layers.Dense(num_classes, activation='softmax')(x)  # Final output layer with softmax activation\n",
        "\n",
        "  # Compile the model\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "\n",
        "input_shape = (11, 11, 16)\n",
        "num_classes = 16\n",
        "#input_shape = X_train.shape[1:]  # Get input shape from training data\n",
        "model = vgg16_with_channel_attention(input_shape, num_classes)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldqJi7KukZ94"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_mA6NfkkdF8",
        "outputId": "508ec705-12f2-42d8-f2d7-ad1de53bde28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 2.4355 - accuracy: 0.2375\n",
            "Epoch 1: accuracy improved from -inf to 0.23748, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 234s 2s/step - loss: 2.4355 - accuracy: 0.2375 - val_loss: 2.1424 - val_accuracy: 0.2386\n",
            "Epoch 2/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.9679 - accuracy: 0.2804\n",
            "Epoch 2: accuracy improved from 0.23748 to 0.28042, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 204s 2s/step - loss: 1.9679 - accuracy: 0.2804 - val_loss: 1.7127 - val_accuracy: 0.3629\n",
            "Epoch 3/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.4878 - accuracy: 0.4310\n",
            "Epoch 3: accuracy improved from 0.28042 to 0.43103, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 210s 2s/step - loss: 1.4878 - accuracy: 0.4310 - val_loss: 1.3427 - val_accuracy: 0.4626\n",
            "Epoch 4/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.2195 - accuracy: 0.5332\n",
            "Epoch 4: accuracy improved from 0.43103 to 0.53318, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 230s 2s/step - loss: 1.2195 - accuracy: 0.5332 - val_loss: 1.3509 - val_accuracy: 0.5137\n",
            "Epoch 5/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 1.0891 - accuracy: 0.5813\n",
            "Epoch 5: accuracy improved from 0.53318 to 0.58133, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 203s 2s/step - loss: 1.0891 - accuracy: 0.5813 - val_loss: 1.0023 - val_accuracy: 0.5803\n",
            "Epoch 6/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.8976 - accuracy: 0.6344\n",
            "Epoch 6: accuracy improved from 0.58133 to 0.63435, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 198s 2s/step - loss: 0.8976 - accuracy: 0.6344 - val_loss: 0.8969 - val_accuracy: 0.6615\n",
            "Epoch 7/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.7729 - accuracy: 0.6926\n",
            "Epoch 7: accuracy improved from 0.63435 to 0.69258, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 229s 2s/step - loss: 0.7729 - accuracy: 0.6926 - val_loss: 0.9279 - val_accuracy: 0.5976\n",
            "Epoch 8/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.6771 - accuracy: 0.7215\n",
            "Epoch 8: accuracy improved from 0.69258 to 0.72154, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 209s 2s/step - loss: 0.6771 - accuracy: 0.7215 - val_loss: 0.8017 - val_accuracy: 0.6747\n",
            "Epoch 9/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.7459\n",
            "Epoch 9: accuracy improved from 0.72154 to 0.74593, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 211s 2s/step - loss: 0.6330 - accuracy: 0.7459 - val_loss: 1.2032 - val_accuracy: 0.6553\n",
            "Epoch 10/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.7440\n",
            "Epoch 10: accuracy did not improve from 0.74593\n",
            "97/97 [==============================] - 204s 2s/step - loss: 0.6906 - accuracy: 0.7440 - val_loss: 0.5876 - val_accuracy: 0.7880\n",
            "Epoch 11/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.8120\n",
            "Epoch 11: accuracy improved from 0.74593 to 0.81197, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 220s 2s/step - loss: 0.5066 - accuracy: 0.8120 - val_loss: 0.5925 - val_accuracy: 0.7862\n",
            "Epoch 12/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.8465\n",
            "Epoch 12: accuracy improved from 0.81197 to 0.84645, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 200s 2s/step - loss: 0.4212 - accuracy: 0.8465 - val_loss: 0.5439 - val_accuracy: 0.8171\n",
            "Epoch 13/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8517\n",
            "Epoch 13: accuracy improved from 0.84645 to 0.85166, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 229s 2s/step - loss: 0.4278 - accuracy: 0.8517 - val_loss: 1.2560 - val_accuracy: 0.7366\n",
            "Epoch 14/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.8227\n",
            "Epoch 14: accuracy did not improve from 0.85166\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.5146 - accuracy: 0.8227 - val_loss: 0.5761 - val_accuracy: 0.7925\n",
            "Epoch 15/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.8598\n",
            "Epoch 15: accuracy improved from 0.85166 to 0.85979, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 205s 2s/step - loss: 0.4219 - accuracy: 0.8598 - val_loss: 0.6728 - val_accuracy: 0.7886\n",
            "Epoch 16/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8783\n",
            "Epoch 16: accuracy improved from 0.85979 to 0.87833, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 232s 2s/step - loss: 0.3643 - accuracy: 0.8783 - val_loss: 0.5141 - val_accuracy: 0.8518\n",
            "Epoch 17/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8780\n",
            "Epoch 17: accuracy did not improve from 0.87833\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.3703 - accuracy: 0.8780 - val_loss: 0.6617 - val_accuracy: 0.8017\n",
            "Epoch 18/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8764\n",
            "Epoch 18: accuracy did not improve from 0.87833\n",
            "97/97 [==============================] - 193s 2s/step - loss: 0.3736 - accuracy: 0.8764 - val_loss: 0.3356 - val_accuracy: 0.9061\n",
            "Epoch 19/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9330\n",
            "Epoch 19: accuracy improved from 0.87833 to 0.93299, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 207s 2s/step - loss: 0.2197 - accuracy: 0.9330 - val_loss: 0.4149 - val_accuracy: 0.8769\n",
            "Epoch 20/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.8761\n",
            "Epoch 20: accuracy did not improve from 0.93299\n",
            "97/97 [==============================] - 211s 2s/step - loss: 0.4259 - accuracy: 0.8761 - val_loss: 0.5313 - val_accuracy: 0.8148\n",
            "Epoch 21/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8936\n",
            "Epoch 21: accuracy did not improve from 0.93299\n",
            "97/97 [==============================] - 212s 2s/step - loss: 0.3865 - accuracy: 0.8936 - val_loss: 0.5081 - val_accuracy: 0.8418\n",
            "Epoch 22/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.9122\n",
            "Epoch 22: accuracy did not improve from 0.93299\n",
            "97/97 [==============================] - 229s 2s/step - loss: 0.2848 - accuracy: 0.9122 - val_loss: 0.3118 - val_accuracy: 0.9130\n",
            "Epoch 23/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.9678\n",
            "Epoch 23: accuracy improved from 0.93299 to 0.96779, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 221s 2s/step - loss: 0.1483 - accuracy: 0.9678 - val_loss: 0.3131 - val_accuracy: 0.9190\n",
            "Epoch 24/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9323\n",
            "Epoch 24: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 208s 2s/step - loss: 0.2136 - accuracy: 0.9323 - val_loss: 0.3608 - val_accuracy: 0.9010\n",
            "Epoch 25/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.8505 - accuracy: 0.7453\n",
            "Epoch 25: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.8505 - accuracy: 0.7453 - val_loss: 0.6055 - val_accuracy: 0.8085\n",
            "Epoch 26/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8504\n",
            "Epoch 26: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.4191 - accuracy: 0.8504 - val_loss: 0.4104 - val_accuracy: 0.8733\n",
            "Epoch 27/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.9066\n",
            "Epoch 27: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 222s 2s/step - loss: 0.2922 - accuracy: 0.9066 - val_loss: 0.4795 - val_accuracy: 0.8679\n",
            "Epoch 28/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.9063\n",
            "Epoch 28: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 225s 2s/step - loss: 0.2821 - accuracy: 0.9063 - val_loss: 0.4555 - val_accuracy: 0.8506\n",
            "Epoch 29/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9382\n",
            "Epoch 29: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 228s 2s/step - loss: 0.1936 - accuracy: 0.9382 - val_loss: 0.3009 - val_accuracy: 0.9200\n",
            "Epoch 30/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9379\n",
            "Epoch 30: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 199s 2s/step - loss: 0.1960 - accuracy: 0.9379 - val_loss: 0.8863 - val_accuracy: 0.8305\n",
            "Epoch 31/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.9092\n",
            "Epoch 31: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 200s 2s/step - loss: 0.3404 - accuracy: 0.9092 - val_loss: 0.3023 - val_accuracy: 0.9139\n",
            "Epoch 32/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9652\n",
            "Epoch 32: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 198s 2s/step - loss: 0.1233 - accuracy: 0.9652 - val_loss: 0.3425 - val_accuracy: 0.9215\n",
            "Epoch 33/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9632\n",
            "Epoch 33: accuracy did not improve from 0.96779\n",
            "97/97 [==============================] - 218s 2s/step - loss: 0.1412 - accuracy: 0.9632 - val_loss: 0.2956 - val_accuracy: 0.9243\n",
            "Epoch 34/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9733\n",
            "Epoch 34: accuracy improved from 0.96779 to 0.97332, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 223s 2s/step - loss: 0.0855 - accuracy: 0.9733 - val_loss: 0.2399 - val_accuracy: 0.9452\n",
            "Epoch 35/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9606\n",
            "Epoch 35: accuracy did not improve from 0.97332\n",
            "97/97 [==============================] - 193s 2s/step - loss: 0.1100 - accuracy: 0.9606 - val_loss: 0.3988 - val_accuracy: 0.9058\n",
            "Epoch 36/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9730\n",
            "Epoch 36: accuracy did not improve from 0.97332\n",
            "97/97 [==============================] - 218s 2s/step - loss: 0.0745 - accuracy: 0.9730 - val_loss: 0.2311 - val_accuracy: 0.9461\n",
            "Epoch 37/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9519\n",
            "Epoch 37: accuracy did not improve from 0.97332\n",
            "97/97 [==============================] - 214s 2s/step - loss: 0.1700 - accuracy: 0.9519 - val_loss: 0.3065 - val_accuracy: 0.9353\n",
            "Epoch 38/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9652\n",
            "Epoch 38: accuracy did not improve from 0.97332\n",
            "97/97 [==============================] - 216s 2s/step - loss: 0.1267 - accuracy: 0.9652 - val_loss: 0.2569 - val_accuracy: 0.9426\n",
            "Epoch 39/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9824\n",
            "Epoch 39: accuracy improved from 0.97332 to 0.98243, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 226s 2s/step - loss: 0.0579 - accuracy: 0.9824 - val_loss: 0.2239 - val_accuracy: 0.9494\n",
            "Epoch 40/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9844\n",
            "Epoch 40: accuracy improved from 0.98243 to 0.98439, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 235s 2s/step - loss: 0.0556 - accuracy: 0.9844 - val_loss: 0.2319 - val_accuracy: 0.9561\n",
            "Epoch 41/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9880\n",
            "Epoch 41: accuracy improved from 0.98439 to 0.98796, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 227s 2s/step - loss: 0.0465 - accuracy: 0.9880 - val_loss: 0.2214 - val_accuracy: 0.9601\n",
            "Epoch 42/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9906\n",
            "Epoch 42: accuracy improved from 0.98796 to 0.99057, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 225s 2s/step - loss: 0.0338 - accuracy: 0.9906 - val_loss: 0.2117 - val_accuracy: 0.9557\n",
            "Epoch 43/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9945\n",
            "Epoch 43: accuracy improved from 0.99057 to 0.99447, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 243s 3s/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 0.2201 - val_accuracy: 0.9592\n",
            "Epoch 44/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9948\n",
            "Epoch 44: accuracy improved from 0.99447 to 0.99480, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 205s 2s/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 0.2114 - val_accuracy: 0.9597\n",
            "Epoch 45/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9935\n",
            "Epoch 45: accuracy did not improve from 0.99480\n",
            "97/97 [==============================] - 203s 2s/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.2142 - val_accuracy: 0.9626\n",
            "Epoch 46/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9948\n",
            "Epoch 46: accuracy did not improve from 0.99480\n",
            "97/97 [==============================] - 229s 2s/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.2562 - val_accuracy: 0.9561\n",
            "Epoch 47/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9954\n",
            "Epoch 47: accuracy improved from 0.99480 to 0.99545, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 228s 2s/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.2467 - val_accuracy: 0.9564\n",
            "Epoch 48/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9886\n",
            "Epoch 48: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 200s 2s/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.2925 - val_accuracy: 0.9387\n",
            "Epoch 49/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.9099\n",
            "Epoch 49: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.3403 - accuracy: 0.9099 - val_loss: 0.3239 - val_accuracy: 0.9228\n",
            "Epoch 50/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.9421\n",
            "Epoch 50: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 199s 2s/step - loss: 0.1949 - accuracy: 0.9421 - val_loss: 0.2502 - val_accuracy: 0.9405\n",
            "Epoch 51/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9834\n",
            "Epoch 51: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 201s 2s/step - loss: 0.0579 - accuracy: 0.9834 - val_loss: 0.1851 - val_accuracy: 0.9601\n",
            "Epoch 52/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9883\n",
            "Epoch 52: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.1867 - val_accuracy: 0.9600\n",
            "Epoch 53/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9896\n",
            "Epoch 53: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 219s 2s/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.2801 - val_accuracy: 0.9367\n",
            "Epoch 54/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9535\n",
            "Epoch 54: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 200s 2s/step - loss: 0.1550 - accuracy: 0.9535 - val_loss: 0.2039 - val_accuracy: 0.9523\n",
            "Epoch 55/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9818\n",
            "Epoch 55: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 218s 2s/step - loss: 0.0683 - accuracy: 0.9818 - val_loss: 0.1849 - val_accuracy: 0.9582\n",
            "Epoch 56/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9896\n",
            "Epoch 56: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 221s 2s/step - loss: 0.0411 - accuracy: 0.9896 - val_loss: 0.1757 - val_accuracy: 0.9660\n",
            "Epoch 57/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9919\n",
            "Epoch 57: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 200s 2s/step - loss: 0.0291 - accuracy: 0.9919 - val_loss: 0.1836 - val_accuracy: 0.9631\n",
            "Epoch 58/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9945\n",
            "Epoch 58: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 202s 2s/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.1658 - val_accuracy: 0.9672\n",
            "Epoch 59/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9938\n",
            "Epoch 59: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 198s 2s/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.1618 - val_accuracy: 0.9688\n",
            "Epoch 60/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9932\n",
            "Epoch 60: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 218s 2s/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.2012 - val_accuracy: 0.9626\n",
            "Epoch 61/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.9079\n",
            "Epoch 61: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 198s 2s/step - loss: 0.3804 - accuracy: 0.9079 - val_loss: 0.4754 - val_accuracy: 0.8683\n",
            "Epoch 62/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9694\n",
            "Epoch 62: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.1163 - accuracy: 0.9694 - val_loss: 0.2537 - val_accuracy: 0.9498\n",
            "Epoch 63/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.9346\n",
            "Epoch 63: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 198s 2s/step - loss: 0.2510 - accuracy: 0.9346 - val_loss: 0.5216 - val_accuracy: 0.8939\n",
            "Epoch 64/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.8998\n",
            "Epoch 64: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.3897 - accuracy: 0.8998 - val_loss: 0.2731 - val_accuracy: 0.9239\n",
            "Epoch 65/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9697\n",
            "Epoch 65: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 218s 2s/step - loss: 0.1138 - accuracy: 0.9697 - val_loss: 0.2279 - val_accuracy: 0.9483\n",
            "Epoch 66/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9850\n",
            "Epoch 66: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 193s 2s/step - loss: 0.0568 - accuracy: 0.9850 - val_loss: 0.2218 - val_accuracy: 0.9514\n",
            "Epoch 67/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9847\n",
            "Epoch 67: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 193s 2s/step - loss: 0.0530 - accuracy: 0.9847 - val_loss: 0.1843 - val_accuracy: 0.9575\n",
            "Epoch 68/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9902\n",
            "Epoch 68: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 192s 2s/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.1909 - val_accuracy: 0.9608\n",
            "Epoch 69/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9922\n",
            "Epoch 69: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 223s 2s/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 0.2073 - val_accuracy: 0.9604\n",
            "Epoch 70/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9928\n",
            "Epoch 70: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 201s 2s/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.2030 - val_accuracy: 0.9617\n",
            "Epoch 71/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9932\n",
            "Epoch 71: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 201s 2s/step - loss: 0.0280 - accuracy: 0.9932 - val_loss: 0.1983 - val_accuracy: 0.9629\n",
            "Epoch 72/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9867\n",
            "Epoch 72: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 199s 2s/step - loss: 0.0465 - accuracy: 0.9867 - val_loss: 0.3773 - val_accuracy: 0.9108\n",
            "Epoch 73/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9720\n",
            "Epoch 73: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 222s 2s/step - loss: 0.0883 - accuracy: 0.9720 - val_loss: 0.1852 - val_accuracy: 0.9562\n",
            "Epoch 74/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9906\n",
            "Epoch 74: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 198s 2s/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.1908 - val_accuracy: 0.9663\n",
            "Epoch 75/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9867\n",
            "Epoch 75: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 194s 2s/step - loss: 0.0461 - accuracy: 0.9867 - val_loss: 0.2757 - val_accuracy: 0.9409\n",
            "Epoch 76/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9769\n",
            "Epoch 76: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 196s 2s/step - loss: 0.0728 - accuracy: 0.9769 - val_loss: 0.2469 - val_accuracy: 0.9454\n",
            "Epoch 77/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9876\n",
            "Epoch 77: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 201s 2s/step - loss: 0.0415 - accuracy: 0.9876 - val_loss: 0.1904 - val_accuracy: 0.9632\n",
            "Epoch 78/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9928\n",
            "Epoch 78: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 201s 2s/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.1780 - val_accuracy: 0.9681\n",
            "Epoch 79/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9818\n",
            "Epoch 79: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.0588 - accuracy: 0.9818 - val_loss: 0.3349 - val_accuracy: 0.9307\n",
            "Epoch 80/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9727\n",
            "Epoch 80: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 194s 2s/step - loss: 0.0992 - accuracy: 0.9727 - val_loss: 0.1640 - val_accuracy: 0.9653\n",
            "Epoch 81/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9932\n",
            "Epoch 81: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 215s 2s/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.1608 - val_accuracy: 0.9691\n",
            "Epoch 82/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9948\n",
            "Epoch 82: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 216s 2s/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.1848 - val_accuracy: 0.9643\n",
            "Epoch 83/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9945\n",
            "Epoch 83: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 214s 2s/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.1609 - val_accuracy: 0.9696\n",
            "Epoch 84/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9954\n",
            "Epoch 84: accuracy did not improve from 0.99545\n",
            "97/97 [==============================] - 216s 2s/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1649 - val_accuracy: 0.9709\n",
            "Epoch 85/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9958\n",
            "Epoch 85: accuracy improved from 0.99545 to 0.99577, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 220s 2s/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1712 - val_accuracy: 0.9706\n",
            "Epoch 86/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9964\n",
            "Epoch 86: accuracy improved from 0.99577 to 0.99642, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 201s 2s/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1928 - val_accuracy: 0.9713\n",
            "Epoch 87/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9964\n",
            "Epoch 87: accuracy did not improve from 0.99642\n",
            "97/97 [==============================] - 202s 2s/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1979 - val_accuracy: 0.9698\n",
            "Epoch 88/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9961\n",
            "Epoch 88: accuracy did not improve from 0.99642\n",
            "97/97 [==============================] - 216s 2s/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: 0.1788 - val_accuracy: 0.9692\n",
            "Epoch 89/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9958\n",
            "Epoch 89: accuracy did not improve from 0.99642\n",
            "97/97 [==============================] - 196s 2s/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.1852 - val_accuracy: 0.9692\n",
            "Epoch 90/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9964\n",
            "Epoch 90: accuracy did not improve from 0.99642\n",
            "97/97 [==============================] - 197s 2s/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 0.1967 - val_accuracy: 0.9707\n",
            "Epoch 91/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9971\n",
            "Epoch 91: accuracy improved from 0.99642 to 0.99707, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 204s 2s/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.2185 - val_accuracy: 0.9628\n",
            "Epoch 92/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9964\n",
            "Epoch 92: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 206s 2s/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.4700 - val_accuracy: 0.9041\n",
            "Epoch 93/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9418\n",
            "Epoch 93: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 194s 2s/step - loss: 0.2333 - accuracy: 0.9418 - val_loss: 0.2360 - val_accuracy: 0.9561\n",
            "Epoch 94/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9763\n",
            "Epoch 94: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 193s 2s/step - loss: 0.1170 - accuracy: 0.9763 - val_loss: 0.2733 - val_accuracy: 0.9505\n",
            "Epoch 95/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9922\n",
            "Epoch 95: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 194s 2s/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.2380 - val_accuracy: 0.9661\n",
            "Epoch 96/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9941\n",
            "Epoch 96: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 196s 2s/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 0.3391 - val_accuracy: 0.9557\n",
            "Epoch 97/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9707\n",
            "Epoch 97: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 195s 2s/step - loss: 0.0964 - accuracy: 0.9707 - val_loss: 0.2926 - val_accuracy: 0.9575\n",
            "Epoch 98/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9922\n",
            "Epoch 98: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 193s 2s/step - loss: 0.0316 - accuracy: 0.9922 - val_loss: 0.1966 - val_accuracy: 0.9716\n",
            "Epoch 99/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9941\n",
            "Epoch 99: accuracy did not improve from 0.99707\n",
            "97/97 [==============================] - 215s 2s/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.2175 - val_accuracy: 0.9714\n",
            "Epoch 100/100\n",
            "97/97 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9974\n",
            "Epoch 100: accuracy improved from 0.99707 to 0.99740, saving model to best-model.hdf5\n",
            "97/97 [==============================] - 198s 2s/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.1850 - val_accuracy: 0.9763\n"
          ]
        }
      ],
      "source": [
        "# checkpoint for saving epochs\n",
        "filepath = \"best-model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "history = model.fit(X_train, y_train,validation_data=(X_test,y_test), epochs=100,batch_size=32,callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gziutkf0RtLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "acc51740-7bfb-4b39-a40c-ad831efb705d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'best-model.hdf5t.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5b78d9e8b90a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best-model.hdf5t.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate remaining epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'best-model.hdf5t.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "# from keras.models import Model\n",
        "# # Load the model\n",
        "# model.load_weights('best-model.hdf5')\n",
        "\n",
        "# # Calculate remaining epochs\n",
        "# initial_epoch = last_completed_epoch + 1\n",
        "# remaining_epochs = total_epochs - initial_epoch\n",
        "\n",
        "# # Resume training\n",
        "# model.fit(X_train, y_train,validation_data=(X_test,y_test), initial_epoch=initial_epoch, epochs=total_epochs, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wYt57nFG48wL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "3edfe186-dc9c-455c-fac8-b681e223c85c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABq9klEQVR4nO3deViU5foH8O8szAz7IjAsIuAGbomiEmlpiamZqWVZx9Ks7GRSFp3OySw92a/odE5miydPnaxOatpitpiWomYWqblvqIiKIKvIDgPMPL8/hhkZGXDAWZjh+7muudJ33nfmnldybu/nfp5HIoQQICIiInIRUkcHQERERGRNTG6IiIjIpTC5ISIiIpfC5IaIiIhcCpMbIiIicilMboiIiMilMLkhIiIil8LkhoiIiFwKkxsiIiJyKUxuiIg6gaioKNx+++2ODoPILpjcEDmJf//735BIJEhISHB0KE7jySefhEQiQWZmZovnLFiwABKJBIcOHbqm94qKioJEIjH7GDdu3DW9NhG1jdzRARCRZVatWoWoqCjs3r0bmZmZ6Nmzp6ND6vCmT5+Od955B6tXr8bChQvNnvPZZ59hwIABuO666675/eLi4vDMM880Ox4WFnbNr01ElmNyQ+QEzpw5g99++w3r1q3Dn//8Z6xatQqLFi1ydFhmVVVVwdPT09FhAAASEhLQs2dPfPbZZ2aTm/T0dJw5cwavvfaaVd4vPDwc999/v1Vei4jaj8NSRE5g1apV8Pf3x4QJEzB16lSsWrXK7HmlpaV4+umnERUVBaVSia5du2LGjBkoLi42nlNbW4u///3v6N27N1QqFUJDQ3HnnXfi9OnTAIDt27dDIpFg+/btJq999uxZSCQSfPzxx8ZjDz74ILy8vHD69Gncdttt8Pb2xvTp0wEAv/zyC+6++25069YNSqUSERERePrpp1FTU9Ms7oyMDNxzzz0ICgqCu7s7YmJisGDBAgDAtm3bIJFI8PXXXze7bvXq1ZBIJEhPT2/x3k2fPh0ZGRnYt29fi9ffd999xmObN2/GiBEj4OfnBy8vL8TExOD5559v8fXbynDPsrKyMHbsWHh6eiIsLAyLFy+GEMLk3KqqKjzzzDOIiIiAUqlETEwM/vWvfzU7DwBWrlyJYcOGwcPDA/7+/rjpppvw008/NTtv586dGDZsGFQqFbp3747//e9/VvtsRB0FkxsiJ7Bq1SrceeedUCgUuO+++3Dq1Cns2bPH5JzKykrceOONeOedd3DrrbfirbfewmOPPYaMjAzk5OQAALRaLW6//Xa89NJLiI+PxxtvvIF58+ahrKwMR44caVdsDQ0NGDt2LIKDg/Gvf/0Ld911FwDgiy++QHV1NebMmYN33nkHY8eOxTvvvIMZM2aYXH/o0CEkJCRg69atmD17Nt566y1MnjwZ3333HQBg1KhRiIiIMJvQrVq1Cj169EBiYmKL8RmSrdWrV5sc12q1+Pzzz3HjjTeiW7duAICjR4/i9ttvh0ajweLFi/HGG2/gjjvuwK+//mrRvaivr0dxcXGzx5UJnVarxbhx46BWq/H6668jPj4eixYtMqnGCSFwxx134M0338S4ceOwZMkSxMTE4Nlnn0VKSorJ67300kt44IEH4ObmhsWLF+Oll15CREQEtm7danJeZmYmpk6dijFjxuCNN96Av78/HnzwQRw9etSiz0fkNAQRdWh//PGHACA2b94shBBCp9OJrl27innz5pmct3DhQgFArFu3rtlr6HQ6IYQQK1asEADEkiVLWjxn27ZtAoDYtm2byfNnzpwRAMRHH31kPDZz5kwBQDz33HPNXq+6urrZsdTUVCGRSMS5c+eMx2666Sbh7e1tcqxpPEIIMX/+fKFUKkVpaanxWGFhoZDL5WLRokXN3udKQ4cOFV27dhVardZ4bNOmTQKA+M9//mM89uabbwoAoqio6KqveaXIyEgBwOwjNTXVeJ7hnj3xxBMmn3XChAlCoVAY33v9+vUCgPi///s/k/eZOnWqkEgkIjMzUwghxKlTp4RUKhVTpkwx+XyG170yvh07dhiPFRYWCqVSKZ555pk2f16ijoyVG6IObtWqVVCr1bj55psBABKJBNOmTcOaNWug1WqN53311VcYOHAgpkyZ0uw1JBKJ8ZzAwEA88cQTLZ7THnPmzGl2zN3d3fjrqqoqFBcX44YbboAQAvv37wcAFBUVYceOHXjooYeM1RNz8cyYMQMajQZffvml8djatWvR0NBgUY/L/fffj5ycHOzYscN4bPXq1VAoFLj77ruNx/z8/AAA33zzDXQ63VVf90oJCQnYvHlzs0fTYS+D5ORk468lEgmSk5NRV1eHLVu2AAB++OEHyGQyPPnkkybXPfPMMxBCYOPGjQCA9evXQ6fTYeHChZBKTf9Kv/LPtG/fvrjxxhuNvw8KCkJMTAyysrLa/FmJOjImN0QdmFarxZo1a3DzzTfjzJkzyMzMRGZmJhISElBQUIC0tDTjuadPn0b//v1bfb3Tp08jJiYGcrn15hLI5XJ07dq12fHs7Gw8+OCDCAgIgJeXF4KCgjBy5EgAQFlZGQAYv1SvFndsbCyGDh1qMjS1atUqXH/99RbNGrv33nshk8mMQ1O1tbX4+uuvMX78ePj7+xvPmzZtGoYPH45HHnkEarUa9957Lz7//HOLE53AwEAkJSU1e0RGRpqcJ5VK0b17d5NjvXv3BqDvbQKAc+fOISwsDN7e3ibn9enTx/g8oP8zlUql6Nu371XjuzKBBAB/f39cunTJos9H5CyY3BB1YFu3bkVeXh7WrFmDXr16GR/33HMPALTYWHwtWqrgNK0SNaVUKptVDLRaLcaMGYMNGzbgb3/7G9avX4/Nmzcbm5HbUxWZMWMGfv75Z+Tk5OD06dP4/fffLZ6ZFBwcjDFjxuCrr75CfX09vvvuO1RUVBj7cQzc3d2xY8cObNmyBQ888AAOHTqEadOmYcyYMS1+fmcik8nMHhdmGpSJnBmTG6IObNWqVQgODsYXX3zR7HHffffh66+/Njar9ujR46pNwT169MCJEydQX1/f4jmGSkZpaanJcUOlwBKHDx/GyZMn8cYbb+Bvf/sbJk2ahKSkpGbrvRiqF5Y0MxuqL5999hlWrVoFNzc3TJs2zeKYpk+fjpKSEmzcuBGrV6+Gj48PJk6c2Ow8qVSK0aNHY8mSJTh27BheeeUVbN26Fdu2bbP4va5Gp9M1Gwo6efIkAP1igAAQGRmJCxcuoKKiwuS8jIwM4/OA/s9Up9Ph2LFjVouPyNkxuSHqoGpqarBu3TrcfvvtmDp1arNHcnIyKioq8O233wIA7rrrLhw8eNDslGnDv8zvuusuFBcX4913323xnMjISMhkMpP+FEC/QrKlDBWCphUBIQTeeustk/OCgoJw0003YcWKFcjOzjYbj0FgYCDGjx+PlStXYtWqVRg3bhwCAwMtjmny5Mnw8PDAv//9b2zcuBF33nknVCqVyTklJSXNrouLiwMAaDQai9/LEk3/DIQQePfdd+Hm5obRo0cDAG677TZotdpmf1ZvvvkmJBIJxo8fD0D/uaRSKRYvXtysIsaKDHVWXMSPqIP69ttvUVFRgTvuuMPs89dffz2CgoKwatUqTJs2Dc8++yy+/PJL3H333XjooYcQHx+PkpISfPvtt1i+fDkGDhyIGTNm4H//+x9SUlKwe/du3HjjjaiqqsKWLVvw+OOPY9KkSfD19cXdd9+Nd955BxKJBD169MD333+PwsJCi2OPjY1Fjx498Je//AW5ubnw8fHBV199Zba34+2338aIESMwePBgPProo4iOjsbZs2exYcMGHDhwwOTcGTNmYOrUqQCAl19+2fKbCcDLywuTJ0829t1cOSQFAIsXL8aOHTswYcIEREZGorCwEP/+97/RtWtXjBgx4qrvkZubi5UrV7b43gYqlQqbNm3CzJkzkZCQgI0bN2LDhg14/vnnERQUBACYOHEibr75ZixYsABnz57FwIED8dNPP+Gbb77BU089hR49egAAevbsiQULFuDll1/GjTfeiDvvvBNKpRJ79uxBWFgYUlNT23SfiFyCo6ZpEVHrJk6cKFQqlaiqqmrxnAcffFC4ubmJ4uJiIYQQFy9eFMnJySI8PFwoFArRtWtXMXPmTOPzQuinaC9YsEBER0cLNzc3ERISIqZOnSpOnz5tPKeoqEjcddddwsPDQ/j7+4s///nP4siRI2angnt6epqN7dixYyIpKUl4eXmJwMBAMXv2bHHw4MFmryGEEEeOHBFTpkwRfn5+QqVSiZiYGPHiiy82e02NRiP8/f2Fr6+vqKmpseQ2mtiwYYMAIEJDQ5tNmxZCiLS0NDFp0iQRFhYmFAqFCAsLE/fdd584efLkVV+7tangkZGRxvMM9+z06dPi1ltvFR4eHkKtVotFixY1i6miokI8/fTTIiwsTLi5uYlevXqJf/7znyZTvA1WrFghBg0aJJRKpfD39xcjR440Lh9giG/ChAnNrhs5cqQYOXLkVT8fkTORCMG6JRE5h4aGBoSFhWHixIn48MMPHR1Ouzz44IP48ssvUVlZ6ehQiFwWe26IyGmsX78eRUVFzVY5JiJqij03RNTh7dq1C4cOHcLLL7+MQYMGGdfLISIyh5UbIurw3nvvPcyZMwfBwcHc6JGIroo9N0RERORSWLkhIiIil8LkhoiIiFxKp2so1ul0uHDhAry9va9pF2QiIiKyHyEEKioqEBYW1mw/uyt1uuTmwoULiIiIcHQYRERE1A7nz59H165dWz2n0yU33t7eAPQ3x8fHx8HREBERkSXKy8sRERFh/B5vTadLbgxDUT4+PkxuiIiInIwlLSVsKCYiIiKXwuSGiIiIXAqTGyIiInIpTG6IiIjIpTC5ISIiIpfC5IaIiIhcCpMbIiIicilMboiIiMilODS52bFjByZOnIiwsDBIJBKsX7/+qtds374dgwcPhlKpRM+ePfHxxx/bPE4iIiJyHg5NbqqqqjBw4EAsW7bMovPPnDmDCRMm4Oabb8aBAwfw1FNP4ZFHHsGPP/5o40iJiIjIWTh0+4Xx48dj/PjxFp+/fPlyREdH44033gAA9OnTBzt37sSbb76JsWPH2ipMIiIiciJO1XOTnp6OpKQkk2Njx45Fenq6gyIiIiKijsapNs7Mz8+HWq02OaZWq1FeXo6amhq4u7s3u0aj0UCj0Rh/X15ebvM4iYiIOqv8slpUahrQM9jLYTE4VXLTHqmpqXjppZccHQYRtaBeq0N5TT3KaxtQXlMPhVyK2BBvi3b+JbKXmjotiio0KKqsRaVGC029FpoGHWrrtait1+p/fmvrUV6j/29dg67ZayjkUijlUijlMqjc9P9VyqVQNv5aIZOgqk7b+P9DPcpqGoy/Nvw/UlFbD6VcBh93OXxUbvBRuaFbgAcWTuwLT6XjvtIzCyvx49F8/HQ0HwdzypDUR43/zhzisHicKrkJCQlBQUGBybGCggL4+PiYrdoAwPz585GSkmL8fXl5OSIiImwaJ1Fn0aDV4ZdTxfhyXw4y8sqhadDpH/Va1Gl16OKpRFd/d3T190BEgDu8lHLkXKppfFQj91INKjQNzV43qU8wXpkyAGoflQM+VfvlltYg/fRFpJ++iIz8cngoZPovIHc3+Kjk8HU3/NoNPu5yBHkrMSjCH1KpcyRyDVodKmobUFXX0PjnrENtgxZCCPQL84XKTeaQuGrrtW1+77KaeqSfvojTRZX6R2ElsoqroNMJKN0akw65vnOjuLIOlWZ+Th2ltl6Hspp6ADUAgPSsi4iP8sc9Q9r23SaEwPmSGhzLK8PRC+XIK6vF46N6oHtQ6xUXTYMWpwoqcfRCGY5dKMfOzGKcLqoyPi+RANV1DRBCOOwfKU6V3CQmJuKHH34wObZ582YkJia2eI1SqYRSqbR1aESdyumiSny5Nwfr9uWgoFzT4nm5pTXILa3BrjMlV31Nb6UcPu5uKKyoxZbjhdh95mcsmtgPdw4O75BVHK1O4FRhBfZnl2LfuUvYdaYE2SXVbX6dZ8fGYO7NPW0QYftcqqrD0Qvlxi+8UwWVKK2uQ3ltQ6tf8BEB7nhl8gDc1DvIovcRQqBOq4NS3v6E6MD5Ury5+SR+PlmEx0b2wN/GxVj0s6LTCfzpg99x9IL5NoWqOq3Z4yo3KYK8lfBRuRkrMPqqixQ+KrcmyascyiuSLSGAugbt5X8ANGhRW69DXWP1R9Og/7WH0jQh9nFvfN3GhNhH5QZNg66xslOPNbuz8ePRAhxr4bOY06DV4YX1R7DhUF6zf1wUVWjwyUPDzF6XVVSJp9YewLEL5WjQCZPn3GQSJPYIxNh+aozpo0awg/9h4tDkprKyEpmZmcbfnzlzBgcOHEBAQAC6deuG+fPnIzc3F//73/8AAI899hjeffdd/PWvf8VDDz2ErVu34vPPP8eGDRsc9RGIOoW8shr8nqWvSPyeZfol7u/hhklx4Ujqo4anUmb8C99NKkVRZS1yLtXgfEk1chqrNF393NE1wANd/d0R4e+OQC8lvFVukDVWLzLyy/HsF4dwOLcMz3xxEN8fuoDUO69DiO+1/WXZoNXhXGMchniKKzX4U0I3DO7mb/HrbDlWgI9+O4OD58uafdnLpBIMCPdFYo8uGBThB61OGL+EymrqUVHbYBxeOFtchaziKhw8X3pNn8sahBDYcrwQSzafxPG8q39JKuRSqORSKN30wysVtQ04X1KDGSt2Y3JcGF64vS8CvVr/R+Wib4/i09/PYUTPQNw9JAK39lVbXH05nFOGN7ecxNaMQuOx5T+fhrdKblGiuPFIPo5e0FfWbu2rRs9gL/QI8kL3IC+o3KTGqpSmQQudAAK9FAjyVsJLKe9wifalqro2Jzf/3XkGa/acBwAoZFL0DvFCb7U3vt6fi59PFiGzsAI9g72bXfevn07gUE4ZAMDX3Q39wnzQL8wH13X1w029g+Dr7madD2UFDk1u/vjjD9x8883G3xuGj2bOnImPP/4YeXl5yM7ONj4fHR2NDRs24Omnn8Zbb72Frl274r///S+ngRPZwNniKnx78AK+O3gBpworTZ6TSSUY2TsId8d3xS19glv813e3Lh6Ij2zb+8aG+ODrx2/A+79kYenmU9h2ogiPfvoHvk0e0a7PUaVpwGe7s/HBL1lmq0ynCivxzdzhV32deq0O/9iYgf/uPGM85qmQYWCEHwZ188OQyAAMjQ6Al4V9D1uOFeCR//2B3NIayz+MDfxxtgSvbczAH+cuGY9FdvFAvzAf9A31QZ9QH2O1wsfdDd4qOdxkphNtKzUNeOOnE/j4t7NYf+ACtp8swosT+uKu+K5m3/NwThn+l34OAPDLqWL8cqoYPio57ogLw4M3RLfYiFpbr8WzXx7CdwcvAACkEuDOwV0R5ueOt9NO4Z8/noCPuxseuL7lHzqdTuCttJMAgEdu7I6UMb0tv1kdUN8wHwDAsbxy6HTiqkOcZ4qr8OZm/edfPKkf7h3aDYrG4beK2gZsPlaAFb+exatTBphcl1lYgY1H8gEAX825AYO7+XW4RK8phyY3o0aNghCixefNrT48atQo7N+/34ZREXVOtfVanMivwO4zJfju0AXjv9AA/ZdI/3BfJHbvgut7dMHQKMu/xNtDLpPi8VE9cVOvINz+zk4cyilDTZ0W7grLhzAuVdXh49/O4pP0syitrgcAeChk6NZYNVL7qLBqVzYO5ZTiYqUGXVqpNFworUHy6n3Yl10KAHjwhijcMyQCMSHexopTW4X76/sE7ZHcaHUCS7ecRM6lGmMvidJNhszCSmP1QymXYtbwaDx6U3cEeCra9PpeSjkWTeyHyXHheG7dYRzPK8czXxyEVApMGWSa4Agh8MoPxwAAt/ZVIzbUB1/tzUFuaQ1W/p6Ndfty8d+ZQ3BDj0CT6+oadHh81T5szSiEVAJMjgvHE6N7ITrQ0/DCeHtrJhZ+cwQ+KjkmxYWbjfWHI3k4WVAJb5UcD4+IbtPn7Ih6BHlBIZeiUtOA85eqEdnFs8VzdTqB5746BE2DDjf2CsQD10eaJCgPj4jG5mMFWLcvB8/eGgP/Jj8H/95+GkIAY/qqER9peaXTUZyq54aIrGvTkTz8eLQARy+U4XRRFbRNxtFlUgmG9wzExOtCcWu/EIeUnPuF+cBbKUeFpgE5l6rRS928VG7O4Zwy3Pt+urF3IqqLB+aM6oHJg8JNqkx7z11CRn4FfjlVjMmDzH8ZbjtRiJS1B3Cpuh7eKjn+OXUgxvUPuebPZkhuSqvrUaVpsOlMlw9+ycI7WzPNPieTSnDPkK6YN7r3NQ/9DYzww7fJw5H6QwZW/HoGC9cfxdCoAHT19zCek3a8EL9nlUApl2LRHf0Q7ueOp0b3wm+nL+LttFPYfbYEsz7ag/fuH4xbYvVLfzRodZi3Zj+2ZhRCKZfi41nDkNiji8l7Pz2mN8pq6vFJ+jk88/lBeKvkxusNtDqBt7acAqD/Iu9Iwyjt5SaTIkbtjcO5+ube1pKbNXvOY9eZEngoZHh1yoBmlZeE6AD0DfXBsbxyrN6dbRziO19SjW8O6KtlyR2oP6w1TG6IOqm04wV4bOU+k2MBngr0C/PBrX3VGD8g9Kp9E7YmkUjQNcADx/PKcb4Nyc0n6WdRVadFr2AvzEvqhfH9Q81WWEbFBCMjvwLbTxSaTW6O5Jbh4Y/3QCeA/uE++Pef4tGti0ez89rDR6Uf4qmobcCF0hqLP1tbnSqowJKf9MMQD1wfCbWP0tjUKpNKcNfgrlZdj8RNJsXzt8XiwPlL2JddipTPD+Kz2ddDJpWgXqvDqxuPA9AnF+F++gRPKpVgRK9ADInyR/Lq/dhyvACP/m8vlt4bh9v6h+LZLw9h45F8KGRSvD9jSLPEBtD/rCya2A/ltQ34en8uHlu5D29Ni8P4AaHGczYczsOpQn3VZtZw56/aGPQN9dEnN3nlJp+3qfyyWqT+oL/3f7k1BhEBzX+OJRIJHh4RjWe+OIj/pZ/Fozd1h5tMiv/sOA2tTuDGXoEYGOFny49iNUxuiDqh2notXvpOPzRw24AQ3DW4K/qF+ULto+xw4+jdAtxxPK8c2Rctn4n0e9ZFAMALt/fFyFZm74yKCcLyn09jx6lis/0Ka/ZkQyeAm3oH4f0H4q0+1Tnczx0Z+RXIsVFy06DV4ZkvDqJOq8PNMUFYPKmfXf585TIp3pwWh9ve+gW7z5Tg/R1ZmDOqB9bszkZWURW6eCowZ1SPZtep3GR47/7BeObzg/j24AU8+dl+rIw+h9+zSiCTSvDunwa1+ucplUrw+tTrUFOnxaaj+Xh89T4svL0vZg2PhlYn8HaavmrzyIjuLlG1MegX7gP8gRZnfwkh8ML6w6jQNCAuwg8zb4hq8bVuHxiK1I0ZKCjX4IfDeUjs3gWf/5EDAB1qVt/VONX2C0RkHe/vyEJ2STXUPkq8PnUgRvdRI8RX1eESGwCIaBzSOH/Jst6UnEv6mVAyqQRDrtIbEB/pD2+lHCVVdTiUW2byXF2DDt8fygMAPDIi2iZruHQ19N1Y+NnaavnPp3Eopww+Kjleu+s6u/75RnbxxKI7+gEAlmw+gfTTF/Fm45DQU0m94K0yn1y4NSZG9w2LgE4Av2eVQCoBlk6Lw639rj4c6CaTYtn0wbj/+m4QAnjpu2N4ZcMxfHfwAjILK+GjkmPWiCirfc6OoG9oY1NxC8nND4fzseV4Idxk+uSvtT4xpVyGGYn6huwPd57BB79koa5Bh/hIfyREB1g/eBthckPUwR3JLUPa8YJWm+9LquqwP/tSi883db6kGsu26fsvFkzoa9PGYGswDANZuobMriz9mjoDwn2v2sfiJpNieE994+r2E4Umz207UYjS6noEeyuN51ibYVjGFk3Fx/PK8VZjpeKlSf0csiDi3fFdMa5fCOq1Ag98uAslVXXoHuSJe4d1a/U6mVSCV6cMwOOjeiDAU4F/Th2IiQPDLH5fmVSClyf1x1/HxQAAPvjlDJ798iAAYPaN3eHTQmLlrGIbk5v88lpcrGw+I/CT9LMAgMdG9kBvCyqE0xP0M6gO5ZTho1/11ybf3LND/uOnJUxuiDqwjYfzMHnZr3j4kz+wcle22XMuVmpwx7s7MeXfvzX7gjbn5e+PQdOgQ2L3Lph4nfnx+Y7EWLmxMLkxDEld3715X4Y5o2L0wxzbTxSZHP96Xy4AYFJcWLtnRF1NuI0qN3UNOjzz+UHUawXG9FVjcgszh2xNIpEg9c4BCPZWGhd9mz++T7Op5C1d+9dxsdj7QlKLU8qvdv3jo3rizWkD4SaToF4r4OvuhgeHR7X5tTo6L6UcUY3/CDieV2HyXGl1HfY2TvO3dAXjLl5KTGn8mWnQCfQL8zH+f+IsmNwQdVDfHbyA5M/2G78UXvr2qPGL20DToMVjK/cip/HLcemWU61WeLafKMRPxwogl0rwkp36L66VofHxfEl1q5/N4PczhuTGshL6yMa/tA/mlKKkqg4AUFZdb5wifeVUZmsK99N/tpYqN2U19Uj5/AB2XfHnfjUf/JKFY3nl8PdwMzsrxp78PRV44x59gjGydxCS+gS36fprjX3KoK74eNYwxEf649UpA1ocDnN2/cJ8AQDH8kyHV38+WQStTiBG7W22ibglDzWZJj/Xyao2AJMbclFCCMxYsRtT3/sN9drmG9h1dF/vz8G8Nfuh1QncOTgck+LC0KATeHzVPuRc0lcwhBB44esj2HP2EryVcijlUhw4X4pfM81/EWoatPj7t0cB6NdpsaQ83REY+lKq6rS41LheTUtyLlXjfEljv02UZclNqK87YkO8IQTwyyl99eb7wxdQp9UhNsTbuEiaLVytcvPV3hys25eLxd8fa9Pr/nRUv9jas2NjEeTt+O1nbuwVhN/nj8YHM4Y45EtyeM9AfDXnBkxwgkplexl+Tq9sKt5yXJ+kj25jUhkT4o3542Px6E3dMdaCXqeOpmMPthO1U86lGuw4qf+i2nO2pNmCYB2BEAIL1h/BoZxSxIboV4PtF+aD00VVWLD+MIQApg2JwKt3DkC9VofTRZU4kluOR/+3F1/OScSq37Pxxd4cSCXAO38ahO0nivDxb2fx9tZTGNGr+eddvj0LZy9WI8hbiXlJvRzwidtH5SaD2keJgnINskuqW11gztBv0z/ct029RCNjghqnhBdhUly4cUjqzsG2Hc4x9NwUVNSirkFnXCnW4GSBfojh6IVy5JfVWrQOjRACZ4r1mxh2pMXWWlskka6duabieq0OP59oX3IDAH8e2XxGm7Ng5YZc0rEm++Nc2UvRUeSX12L1rmwcyS3Hl3tzsPj7Y5j2/u94/mt9YjM9oRtS7xwAmVQClZsM/3lgCAK9FDiWV47p/91lXC/khQl9MSomGH8e2R0KmRS7z5Q0G8ZIP33RuOT8CxP6OF1p3tK+m11tHJIyGNVb/xf/jpNFOFNchT/OXYJUghZXubWWQC8FlHIphNCvQ3IlQ3ID6BucLVFSpd/kEtBvo0Cdg6Fyc7qoErX1+sUr/zh7CeW1DQjwVCAuouMkuvbA5IZcUtN/vTTdXK8jMWxQGO7njnmjeyGpj9r4L/mHhkfj/yb3N1l3JdzPHe/dHw83mQT7s0shBHDfsG6Y1dggGerrjqlD9P0h7267vBptQXktnvhsH3QCuGtwV9zRhlknHUW3AMtmTP3eWLmxtJnYYEiUP7yUclysqsP/NQ4BDe8ZaPMZRhKJxPhnnlNq+tmEEDhVcHlPr7Tjlv0cG6o24X7uNpm+Th1TsLcSgV4K6ARwIl+fFG/NKACgb5q3VVN8R8XkhlxS052NMwsrLZ5pY0+GWQ1Dovzx9Jje+O/MIfj1uVtw4v/GYeHEvmZ7E4ZGBWDxpP6QSoARPQObLco2Z2QPyKUS/HKqGPuzL6Feq0Py6n0orqxDbIg3/m9yf6drDASAro3JjaHfyJzc0hpkl1RbtL7NldxkUoxonO6dZmwkts8MozA/8303+eW1qGiy6/ivmcXGf5G3JqsxuTHuuUSdgkQiQZ9Q074bQ0I8+optKDoDJjfkkgzDUp6NGy1aMkXa3gwxGv5CMmhph22D+4Z1w+/zR+N/Dw1rNqU2IsDD+KX8ztZM/GNjhrHhePn98W3aeLIjsaRyYxiK6x/u265ht6ZTXT0UMrs1Uba01s3JxqpN9yBPhPioUFOvRboFs6bOMrnptC7vEF6GrKJKZBVXQS6V4KbeHa/n0NaY3JDLKa+tN06Nvr9xpc2OODR1vIXkxhLBPqpmWwUYPH5zT0gl+s/8351nAAD/umcgopz4y66bcTp4y+vBGNe3aecqqiObJDfj+oXYdCPLplqaMXWqsd8mRu2NWxqbQbdZ8HNsGJZy5j9vah/jdPAL5ca/8xK6Bzhdj501MLkhl5PRONwT5qsyVjF+O33RopK+vVTXNRi/hPqEWndKdnSgp8lqrn8e6ZxTOZuKCLhc3WhoYWp/e/ttDEJ93RHXuCngPUMtW+zMGlqq3Bj6bXqpvXFLjD65STteeNW1fgw/V92Z3HQ6hhlTGfkV+OmYvt+mMw5JAUxuyAUdu6BfxKpPqA9i1N4I9VVB06CzqKRvLyfyKyCEfrZMsLf1m1afHN0L3ko5RvYOwrO3xlj99e1N7a2CQiaFVieQZ2ZW0YXGfhupRN/D1F7/eSAeX81JbHeC1B7Gys2Vw1KF+iS9t9oLw3sGQimXIre0xjhcZY5OJ3D2IoelOqvoQE+o3KSortNi9xl9st+eKeCugMkNuRxDo27fMB9IJBKMirG8pG8vhhjbMyRliR5BXtj74hh89OBQyC1Y6r6jk0olxsX8zDWHG6aAD2hnv42B2keF+Ej7bg5oqNzkldZC17gatRACmY1JTG+1N9wVMtzQQ59wpTXOgDEnv7wWtfU6yJvcL+o8ZFIJYkMu/53SM9gLkV06Z5Lr/H/rEV3hykbdW2L1yc3WjKuX9O3F0G/T10bJDQAo5NIW+3KckXEbBjMzpn4/fW1DUo4U4quCVALUaXUoatz0MK9MP1NKLpUgqvHL6ZY++uGF1pJ0w5BUtwAPl0hqqe36NVlRe3Rs56zaAExuyMU0aHU40diIaUgcbujRBQqZFDmXanC6qMqR4RldSzNxZ2XouzE3Y8qwn1RCGxfv6wjcZFKENK6nY2iENyzeFx3oaVy12JCk7z13CZca98C6EqeBU9PtQkb36Zz9NgCTG3IxZ4qrUNegg6dCZpxh46mUG7/0OsLQlE4nkJFv22EpV9TSjKmzxVU4d7G6TftJdTSGvpsLjX03l5uJvS6f46ffA0sn9JshmnOWM6U6vYFd/QAAAZ4KDO7m59BYHIl7S5FLMQxJxYR4mwzJ3BwTjF9OFWPbiULMvqm71d/3s93Z+OePJyCV6NepUbpJoZTLMK5fSLN9nHIu1aBS0wCFTIruQfwSspRhC4YrKzc/Nm4SeX33APg46ZTXcD937MElY1OxoXLTK9h0Jt0tscHIyK9AWkYhJptZZPAMKzedXv9wX7w5bSC6BXh26qHJzvvJySUZkpsrd3K+ubGkv/tMCSpqW99Zuq2EEFi2LRMlVXUorqxDbmkNsoqqcDyvHG9uOdlsFowhxl5qr2aL8FHLIlpYpXhTY3Izzomnu1+51s3JwsvNxE0ZZr78fKLQ7JR4TgMnAJgyqGuH2jTVEfg3K3UoQgj85+fT+O10cbuuN+wpdeVwT3SgJ6IDPdGgE/g1s32v3ZKjF8qRc6kG7m4yfJc8AuvnDsfnf040rpny7YELJuez36Z9DMlNcWUdqhq3Jcgvq8X+7FIAwK3OnNz46T9bbmlN40ypy9PAm4qL8Ie/hxvKaxvwx7lLJs/Va3XGmWQclqLOjskNdSi/nb6I1I0Z+OuXh9p1vXEauJnEYWRv/Qq0v2Zad72bjUfyAOiX7x/Q1RdxEX4YFh2AexsXgvt6f47JLK2Wtl2g1vm6u8HXXT/sZGi83XxMX7UZ3M3P5ptc2lLTys2FslpU1WnhJpM0S1Jk0paXNsi5VIMGnYDK7XKDMlFnxeSGOpQjufoF+HIu1aCsum3DR4UVtSiu1EAi0ffcXMnQh3CxSnPtgTYSQmDjkcZhkf6mlYPxA0KhkEtxsqDSmHQBTSs31l2ZuDO4csaUcUiqv/NWbQDTVYqbzpQyN2xpmDWVdkVyc6ZYP5QV1cXTpZYAIGoPJjfUoRhmEQHA8fzyVs5szpBARHfxhIeiea+8V+NeQRW1Dc2ea69ThZXIKqqCQiY1fukY+Lq7IamxR2L9gVwApvte2XKNG1d1ecZUNS5V1Rm3XHD27SUMyU2lpgF7z+qHm3qpzSe/N/UOgkwqQWZhJbIvXu4/ympc5oBN6kRMbqiDMVQ1ACAjr63JTWNFJMx80uCt0ic3lRrrJTebGqs2I3oFml0Zd3KcfkbLNwdyodUJk32v/DwUVoujs2g6Y2rL8QJodQJ9Qn2cfhVWd4UMAZ76n4dtjTvY9w42n9z4urthSGOz6NYmqxUbtl2IcvJ7QWQNTG6ow6hr0CGz8PK+OU2rOJYwNBO3VBHxMiQ3VqzctDQkZTAqJhh+Hm4oKNcg/fRFNhNfo6Yzpn50gVlSTRmqN0cvXJ5N1xLDrKmmQ1OcBk50GZMb6jAyCyvRoLvceHu8nZWblpIbb6W+smKtys25i/rp3jKpBGNaWAlUIZdiwoBQAMDX+3OZ3FwjQ3KTkV+BHaf0s96cvd/GwJDcGFw5U6qpWxp3et6VVWKcOXaGw1JERkxuqMPIaOyxUfsoAQAnCiqg1Vm2F1Rtvda49HxLiYO1KzeGqk1i9y7w92x5iGlK42Jrm47kGactM7lpn27Gyk0N6hp0iA70bDUJcCbhTTa6dJNJWh1q6xHkicguHqjT6rAzsxi19VpcaNwtncNSRExuqAMxVDVu7RsClZsUtfU6nLto2V5QJxsTIX8PN2NydCVDQ3FlXYNx9+VrYei3GXuVykF8pD+6+rujqk5r3PeKM6XaJ8xPBUmTiUC39lNDInGNmUFNKzfdA1tf4FEikeDmxinhW48XGvttfFRyY+8OUWfG5IY6DMNsp35hPohpnCliad/N8SYrE7f0ZWdoKBYCqK7XXlOseWU1OHC+FBIJMLZf65vTSSQSY/UGANzdZE7fAOsoSrkMoU3WcHGVfhvAtHLTWr+NgaHvZtuJQpwubOy3CfJymWSP6FowuaEOwzAsFRvqYxy2sbTvZluGfiPB1qZXK+VSyBvX/7jWLRgMVZshkf4I9r76gmmT4i4nNzEh3pBxHZJ269o4NBXiozJuEugKmlZurtx2wZxh0QHwVMhQWKHB94f0q2BHd/GwWXxEzoTJDXUI+gX46iCVADFqb8Q2LsLXdPG7luw9dwmbjuZDIgHuHNy1xfMkEonV+m4M/TaWrq/SM9gL13X1BcB+m2tl2DdpbD+1Sy1W19W/aXJz9cqNUi7Djb30q24bZo5FB7pG/xHRtXJ4crNs2TJERUVBpVIhISEBu3fvbvHc+vp6LF68GD169IBKpcLAgQOxadMmO0ZLtmJY/yUq0BPuChliGxOAjKss5CeEwCsbjgEA7omPuGriYFzIrw0zppb8dAK9F2xE34WbMGjxT7j+1TTsOatfPK4tM3VSxvRG9yBP3DOk5QSMru7xUT3x6E3d8VRSb0eHYlW+7m7Gfpm+ob4WXWNYONLQQhbNmVJEAIDmy7ja0dq1a5GSkoLly5cjISEBS5cuxdixY3HixAkEBwc3O/+FF17AypUr8cEHHyA2NhY//vgjpkyZgt9++w2DBg1ywCcgazFOkQ7xMflvzqUalNfWw8fMAnkA8MPhfOzLLoW7mwwpt179y87YVNyGys1ne86jTqtDnRaortMC0A9pXd89AF39LR8GGBUTbNwXiNqvWxcPPH9bH0eHYXUSiQTL749HQXktulk4vDQqNsjk99wNnEjPocnNkiVLMHv2bMyaNQsAsHz5cmzYsAErVqzAc8891+z8Tz/9FAsWLMBtt90GAJgzZw62bNmCN954AytXrrRr7GRdV+635OvhhjBfFS6U1eJEfgWGRgU0u0bToMU/NmUAAB69qbtFGycakiRL17oprtSgqEK/X9VPT93U+L46aBp0nPFEVjcsuvnPeWuCvVUY2NUXB3P0e7JxN3AiPYcNS9XV1WHv3r1ISkq6HIxUiqSkJKSnp5u9RqPRQKUy/QJzd3fHzp07W3wfjUaD8vJykwd1PIZZUbEhl4eVjENTLTQVf5p+Dtkl1Qj2VuLPI7tb9D5t7bkxDpd18UQvtTd6qb3RP9wX8ZH+ZvevIrI3w4J+Qd5KY2WSqLNzWHJTXFwMrVYLtdp0Gq1arUZ+fr7Za8aOHYslS5bg1KlT0Ol02Lx5M9atW4e8vLwW3yc1NRW+vr7GR0REhFU/B107TYPWuO1C032hDE3Fx8w0FZdW1+GdrZkAgGdu7W1xotHWnhtDRSnWzC7jRB3B5EFh8FbJMaZv60sSEHUmDm8obou33noLvXr1QmxsLBQKBZKTkzFr1ixIpS1/jPnz56OsrMz4OH/+vB0jJkucLqxCg07ARyVHmO/lylyfVpqK392aibKaesSGeGNqvOUJa1srN9wugTq6yC6e2P/iGLw6ZYCjQyHqMByW3AQGBkImk6GgoMDkeEFBAUJCzM9ACQoKwvr161FVVYVz584hIyMDXl5e6N695SEJpVIJHx8fkwd1LMbqSKjpAnyGnpYT+RUmKwqfLa7CJ+lnAQDP39anTWvGeBsaijWWrXNzjMkNOQF5K6sZE3VGDvs/QqFQID4+HmlpacZjOp0OaWlpSExMbPValUqF8PBwNDQ04KuvvsKkSZNsHS7ZkKEyc+UCfFFdPKGQS1Fdp0V2SbXx+MvfH0O9VmBk7yDc1Nt0tsjVGGdLWTAsVdegw+mixuEyNg8TETkNh6b7KSkp+OCDD/DJJ5/g+PHjmDNnDqqqqoyzp2bMmIH58+cbz9+1axfWrVuHrKws/PLLLxg3bhx0Oh3++te/OuojkBUYFuq7sq9FLpM22YZBnwBtyyhEWkYh5FIJFk7s2+b3MgxLVVgwLJVZWIl6rX647Modm4mIqONyaGv9tGnTUFRUhIULFyI/Px9xcXHYtGmTsck4OzvbpJ+mtrYWL7zwArKysuDl5YXbbrsNn376Kfz8/Bz0CehaCSFa7WuJDfHG4dwyHM+rwC2xaiz+Xr9g30MjotEjqO2rsRobii1IbloaLiMioo7N4fMGk5OTkZycbPa57du3m/x+5MiROHbsmB2iInspqtTgYpV+2wVz++nENtlj6qNfz+BMcRUCvZR44pae7Xo/w+aZlgxLGapFfThTiojIqTg8uaHO7fgV2y5cydDrsi+7FL9mFgMAnhsfC+8WViy+Gi9l4yJ+FlVuKhpjYDMxEZEzYXJDNnMopxS/Zl6EQi6FsvGhcpMhzM8dPYO94OvuZlygr6UEwrCoX3GlBgAQF+GHOweFmz3XEl4WVm6uNlxGREQdF5MbsomSqjpM/++uVntbAr2UAPRTvFsa+gnwVEDto0RBuT65eemOfte0E7S3saG49angRRWXh8tiOCxFRORUmNyQTby15SQqahvQ1d8dg7r5Q1OvhaZBh5rGad355bXGagwAxEX4t/ha/cN8UVBeiHuGdMXACL9risu7yVRwIUSLjcKG9W2iAz2hcms+XEZERB0XkxuyutNFlVi1KxsA8I+7rsPwnoHNzqmorUdWURVOF1VCJpVgeM8uLb7ec+NjMaCrLx4eEX3NsRmGpXQCqKnXtrhtA/ttiIicF5Mbsrp/bMxAg07glthgs4kNAHir3DAwws+iSkwvtTeeMjOTqj3c3WSQSvTJTWVtQyvJDfttiIicFdfsJqvalXURPx0rgFQCzB8f6+hwmpFIJBZtnmmcBs6ViYmInA6TG7IanU7g1R+OAwDuHdYNvaxUbbE2wzTylqaD19ZrcbqoCgArN0REzojJDVnNd4cu4GBOGTwVMjyd1NvR4bToavtLZRZWQqsT8PNwQ4iPyuw5RETUcTG5Iauordfi9U0nAABzRvVAkLfSwRG1zOsq08GNO4GHcNsFIiJnxOSGrOKrfTnILa1BiI8KD4/o7uhwWnW1/aXYTExE5NyY3JBVbD1eCACYcUOk2W0UOpKrrVJ8ecPMjtkzRERErWNyQ9esrkGH9KyLAICRvYMcHM3VGRfyM1O5EUIgI1+/xk1fVm6IiJwSkxtqlU4nsOlIPl5cfwT5ZbVmz/njXAmq67QI9FKiT0jHTwha2xk8v7wWpdX1kEkl6BnsZe/QiIjICriIH5klhMDmYwVYuuWUscG2StOAJdPimp3788kiAMBNvQKvad8nezHsDG5unZuMxpWJewRx2wUiImfF5Iaa+e10MVJ/yMDh3DIAgFIuhaZBhx+P5qO6rvmqvjtOFgMAbnKCISmgSc+NmWGp85eqAQBRXTztGhMREVkPh6XIxIXSGjy4Yg8O55bBQyHDnFE9kD5/NLoFeKCqTovNxwpMzi+sqDU24I7oZX6rhY7Gu5V1bgobdx9Xc30bIiKnxeSGTGw5XoA6rQ59Q33wy19vxt/GxSLAU4FJcWEAgG8OXDA5/5fGqk3/cB8EenXctW2aaq1yU1ih7ysK7sDr9BARUeuY3JCJtMYp3XfEhaFLk2RlUlw4AGDHySKUVNUZj+84Zei3cY4hKQCt7i1VWKGv3AT7MLkhInJWTG7IqErTgPTT+indSX2CTZ7rGeyF/uE+aNAJbDikr97odAK/nNJXbpxhCrjB5XVumq9QbBiWCvbmsBQRkbNickNGOzOLUafVoVuAB3oENZ8GPbmxerO+cWjq6IVylFTVwUspx+BIf7vGei28W1mh2FC56cjbRxARUeuY3JBR2nF9s/DoPsFm91SaODAMEgmw99wlnC+pxs8n9UNYiT26wE3mPD9KTXtuhBDG4w1aHS5WcViKiMjZOc83EtmUTiewNUPfPzM6Vm32HLWPCjf06AIA+OZArtNNATcw9Nw06AQ0DTrj8YtVdRACkEqALp5MboiInBWTGwIAHMotQ3GlBl5KOYZFB7R4nqGx+PM/crAv+xIAYKQTNRMDgKdCDkNhqunQlKHfJtBLCZkTLEZIRETmMbkhAMDWxiGpm3oHQiFv+cdiXP8QKORSZJdUo0EnENXFA926eNgrTKuQSiXwUjRf66agvHEaOIekiIicGpMbAgBsaZwC3tKQlIGPys1kJpWzDUkZmFvrxtBMrOZMKSIip8bkhpBXVoNjeeWQSIBRMVdPVgxDU4BzrW/T1OW1bi5PBzcu4MfKDRGRU+PeUoStGfqqzeBu/iYL97VkVEwQIrt4QFOvQ2Jjg7Gzaa1yE8TKDRGRU2NyQ8ZViW+JDb7KmXpKuQzfPzECAoCn0jl/hLzM7C91eQE/Vm6IiJyZc34zkdXU1Gnxa6Z+SndSn9b7bZryVrnZKiS78FY1T26KuK8UEZFLYM9NJ/drZjE0DTqE+7mjt7r5qsSuysvMKsWX95XisBQRkTNjctPJbTuhH5JKamFVYlflpdRXngzJjU4nUFTBYSkiIlfA5KaTO5ZXDgAY2srCfa7oys0zL1XXoUGn34oh0IKmaiIi6rgcntwsW7YMUVFRUKlUSEhIwO7du1s9f+nSpYiJiYG7uzsiIiLw9NNPo7a21k7RuhYhBLKKqgDA7EaZrsyweaZhtpRhSCrAU9HqIoZERNTxOfRv8bVr1yIlJQWLFi3Cvn37MHDgQIwdOxaFhYVmz1+9ejWee+45LFq0CMePH8eHH36ItWvX4vnnn7dz5K7hUnU9ymrqIZEA0YGejg7Hrq5sKDauTswhKSIip+fQ5GbJkiWYPXs2Zs2ahb59+2L58uXw8PDAihUrzJ7/22+/Yfjw4fjTn/6EqKgo3HrrrbjvvvuuWu0h87KKKgEAYb7uULnJHByNfRmGpSquqNywmZiIyPk5LLmpq6vD3r17kZSUdDkYqRRJSUlIT083e80NN9yAvXv3GpOZrKws/PDDD7jttttafB+NRoPy8nKTB+kZhqS6B3Wuqg3QfJ0bNhMTEbkOh61zU1xcDK1WC7XadG0VtVqNjIwMs9f86U9/QnFxMUaMGAEhBBoaGvDYY4+1OiyVmpqKl156yaqxu4rTxfrKTfdONiQFNB+WKuSwFBGRy3Cqzsnt27fj1Vdfxb///W/s27cP69atw4YNG/Dyyy+3eM38+fNRVlZmfJw/f96OEXdslys3nauZGLg8FfzKhmImN0REzs9hlZvAwEDIZDIUFBSYHC8oKEBISIjZa1588UU88MADeOSRRwAAAwYMQFVVFR599FEsWLAAUmnzXE2pVEKp5BeWOWeKO/GwlKHnRsOeGyIiV+Owyo1CoUB8fDzS0tKMx3Q6HdLS0pCYmGj2murq6mYJjEymb4QVQtguWBfUoNXh3EV9ctPZZkoBl3tu6hp00DRoL+8IzsoNEZHTc+jeUikpKZg5cyaGDBmCYcOGYenSpaiqqsKsWbMAADNmzEB4eDhSU1MBABMnTsSSJUswaNAgJCQkIDMzEy+++CImTpxoTHLIMjmXalCvFVC5SRHm6+7ocOzOq8mGn5W1DU02zWTlhojI2Tk0uZk2bRqKioqwcOFC5OfnIy4uDps2bTI2GWdnZ5tUal544QVIJBK88MILyM3NRVBQECZOnIhXXnnFUR/BaWU1NhNHdfGEVNp5tl0wkEkl8FDIUF2nxYXSWmgadACAYB9WboiInJ3DdwVPTk5GcnKy2ee2b99u8nu5XI5FixZh0aJFdojMtXXWlYmb8lLKUV2nNSZ63ip5p1vvh4jIFTnVbCmynqxO3ExsYJgOfrox0WO/DRGRa2By00kZVifujM3EBl4q/XTw0433Qs2ZUkRELoHJTSfVmde4MTBsnpnFyg0RkUthctMJVdTWG9d16czDUoYZU2cae264xg0RkWtgctMJGRbvC/RSwqdxaKYzMizkV1vfOFOKlRsiIpfA5KYTMg5JdeJ+G8B0rRsACGJyQ0TkEpjcdEKcKaVnmC1lwAX8iIhcA5ObTsgwU6qzJzdXVm64gB8RkWtgctMJXR6W6rwzpYDLPTcG7LkhInINTG46GZ1OdOrdwJtqWrlxd5M1q+QQEZFzYnLTyeSX16KmXgu5VIKIAA9Hh+NQTXtugn2UkEg63x5bRESuiMlNJ2Oo2nQL8ICbrHP/8Xs3mQavZjMxEZHL6Nzfbp0Qm4kvazoMFcRmYiIil8HkppM5zW0XjJomN2wmJiJyHUxuOhnjGjedfAE/4IqeGw5LERG5DCY3nQx3A7/Mk5UbIiKXxLmvLmzZtkys3pWN7kGe6Bfmiz6h3sgtrQHAYSkAcJNJoXKTorZexwX8iIhcCJMbF3Wpqg5vpZ1CXYMOuaU1+OVUsfE5b5UcgV4KB0bXcYT5uiOruApRXVjJIiJyFUxuXNTaP86jrkGH2BBvPJAYiWMXynH0QjlOF1birsFduaZLo/88EI+8stpOv+YPEZErYXLjgrQ6gU/TzwEAHhoejXuGRjg4oo6rl9obvdTejg6DiIisiA3FLmhrRiFyS2vg5+GGO+LCHB0OERGRXTG5cUH/Sz8LAJg2NAIqN5ljgyEiIrIzJjcuJrOwEr+cKoZEAtyfEOnocIiIiOyOyY2LWfm7vtdmdKyaTbJERNQpMblxIZWaBny5NwcAMPMGVm2IiKhzYnLjQtbty0GlpgHdgzwxvEego8MhIiJyCCY3LkIIgU9+OwsAmJkYBamU69gQEVHnxOTGRaRnXcTpoip4KmS4c3C4o8MhIiJyGCY3LmLdvlwAwB1x4fBWuTk4GiIiIsdhcuMCauu12HQkHwAwZRCrNkRE1LkxuXEBaccLUalpQLifO4ZE+js6HCIiIodicuMC1h8wDEmFsZGYiIg6PSY3Tq60ug7bTxQCACbHcUiKiIioQyQ3y5YtQ1RUFFQqFRISErB79+4Wzx01ahQkEkmzx4QJE+wYccfxw+F81GsFYkO8ERPC3a2JiIgcntysXbsWKSkpWLRoEfbt24eBAwdi7NixKCwsNHv+unXrkJeXZ3wcOXIEMpkMd999t50j7xgMQ1KT2UhMREQEoAMkN0uWLMHs2bMxa9Ys9O3bF8uXL4eHhwdWrFhh9vyAgACEhIQYH5s3b4aHh0enTG5yS2uw+0wJJBLgjoFhjg6HiIioQ3BoclNXV4e9e/ciKSnJeEwqlSIpKQnp6ekWvcaHH36Ie++9F56enmaf12g0KC8vN3m4im8PXAAADIsKQJifu4OjISIi6hgcmtwUFxdDq9VCrVabHFer1cjPz7/q9bt378aRI0fwyCOPtHhOamoqfH19jY+IiIhrjrujWL+fQ1JERERXcviw1LX48MMPMWDAAAwbNqzFc+bPn4+ysjLj4/z583aM0HaO55XjREEFFDIpbusf6uhwiIiIOgy5I988MDAQMpkMBQUFJscLCgoQEhLS6rVVVVVYs2YNFi9e3Op5SqUSSqXymmPtaAyNxDfHBsHXg9stEBERGTi0cqNQKBAfH4+0tDTjMZ1Oh7S0NCQmJrZ67RdffAGNRoP777/f1mF2SIbtFri2DRERkSmHVm4AICUlBTNnzsSQIUMwbNgwLF26FFVVVZg1axYAYMaMGQgPD0dqaqrJdR9++CEmT56MLl26OCJshyqvrce5i9UAgBt6BDo4GiIioo7F4cnNtGnTUFRUhIULFyI/Px9xcXHYtGmTsck4OzsbUqlpgenEiRPYuXMnfvrpJ0eE7HAn8ysAAKG+Kg5JERERXcHhyQ0AJCcnIzk52exz27dvb3YsJiYGQggbR9VxZTQmN1yRmIiIqDmnni3VWZ1gckNERNSiNic3UVFRWLx4MbKzs20RD1kgI1+/EGEskxsiIqJm2pzcPPXUU1i3bh26d++OMWPGYM2aNdBoNLaIjcwQQhiHpWJDfBwcDRERUcfTruTmwIED2L17N/r06YMnnngCoaGhSE5Oxr59+2wRIzWRV1aLitoGyKUS9AjycnQ4REREHU67e24GDx6Mt99+GxcuXMCiRYvw3//+F0OHDkVcXBxWrFjRqRt+bckwJNU9yBMKOVumiIiIrtTu2VL19fX4+uuv8dFHH2Hz5s24/vrr8fDDDyMnJwfPP/88tmzZgtWrV1szVgI4JEVERHQVbU5u9u3bh48++gifffYZpFIpZsyYgTfffBOxsbHGc6ZMmYKhQ4daNVDS40wpIiKi1rU5uRk6dCjGjBmD9957D5MnT4abW/NF5KKjo3HvvfdaJUAydcJYuWFyQ0REZE6bk5usrCxERka2eo6npyc++uijdgdF5tU16JBZWAmAlRsiIqKWtLkjtbCwELt27Wp2fNeuXfjjjz+sEhSZl1VciQadgLdSjnA/d0eHQ0RE1CG1ObmZO3cuzp8/3+x4bm4u5s6da5WgyLym/TYSicTB0RAREXVMbU5ujh07hsGDBzc7PmjQIBw7dswqQZF5x/PYTExERHQ1bU5ulEolCgoKmh3Py8uDXN4h9uF0WSe47QIREdFVtTm5ufXWWzF//nyUlZUZj5WWluL555/HmDFjrBocmTLOlArlGjdEREQtaXOp5V//+hduuukmREZGYtCgQQCAAwcOQK1W49NPP7V6gKRXVl2PC2W1AIDealZuiIiIWtLm5CY8PByHDh3CqlWrcPDgQbi7u2PWrFm47777zK55Q9ZxokBftQnzVcHXnfeZiIioJe1qkvH09MSjjz5q7VioFcZ+Gw5JERERtardHcDHjh1DdnY26urqTI7fcccd1xwUNZfBbReIiIgs0q4ViqdMmYLDhw9DIpEYd/82rLui1WqtGyEBaLphJpMbIiKi1rR5ttS8efMQHR2NwsJCeHh44OjRo9ixYweGDBmC7du32yBEEkLgJCs3REREFmlz5SY9PR1bt25FYGAgpFIppFIpRowYgdTUVDz55JPYv3+/LeLs1HJLa1ChaYCbTILugV6ODoeIiKhDa3PlRqvVwttbXz0IDAzEhQsXAACRkZE4ceKEdaMjAEBG48rEPYK8oJC3+Y+MiIioU2lz5aZ///44ePAgoqOjkZCQgNdffx0KhQLvv/8+unfvbosYO72MxplSHJIiIiK6ujYnNy+88AKqqqoAAIsXL8btt9+OG2+8EV26dMHatWutHiABR3L1yU2/ME4DJyIiupo2Jzdjx441/rpnz57IyMhASUkJ/P39uVO1jRzN02910T/M18GREBERdXxtauCor6+HXC7HkSNHTI4HBAQwsbGRsup6nC+pAQD0Y3JDRER0VW1Kbtzc3NCtWzeuZWNHRy/oqzYRAe7w9eC2C0RERFfT5qk3CxYswPPPP4+SkhJbxENXONKY3PQLZdWGiIjIEm3uuXn33XeRmZmJsLAwREZGwtPT0+T5ffv2WS04Ao5e0DcT9w9nMzEREZEl2pzcTJ482QZhUEuO5DZWbsJZuSEiIrJEm5ObRYsW2SIOMqNK04CsYv20e86UIiIisgyXu+3AMvLLIQQQ7K1EkLfS0eEQERE5hTZXbqRSaavTvjmTynoMi/f155AUERGRxdpcufn666+xbt0642Pt2rV47rnnEBoaivfff7/NASxbtgxRUVFQqVRISEjA7t27Wz2/tLQUc+fORWhoKJRKJXr37o0ffvihze/rDAz9Nv25MjEREZHF2ly5mTRpUrNjU6dORb9+/bB27Vo8/PDDFr/W2rVrkZKSguXLlyMhIQFLly7F2LFjceLECQQHBzc7v66uDmPGjEFwcDC+/PJLhIeH49y5c/Dz82vrx3AKRxpnSrGZmIiIyHJtTm5acv311+PRRx9t0zVLlizB7NmzMWvWLADA8uXLsWHDBqxYsQLPPfdcs/NXrFiBkpIS/Pbbb3Bz0y9oFxUVdc2xd0SaBi1OFeh3A+eeUkRERJazSkNxTU0N3n77bYSHh1t8TV1dHfbu3YukpKTLwUilSEpKQnp6utlrvv32WyQmJmLu3LlQq9Xo378/Xn31VZfs8zmZX4kGnYCfhxvC/dwdHQ4REZHTaHPl5soNMoUQqKiogIeHB1auXGnx6xQXF0Or1UKtVpscV6vVyMjIMHtNVlYWtm7diunTp+OHH35AZmYmHn/8cdTX17c4RV2j0UCj0Rh/X15ebnGMjmRYmbh/mC/37SIiImqDNic3b775psmXrVQqRVBQEBISEuDv72/V4K6k0+kQHByM999/HzKZDPHx8cjNzcU///nPFpOb1NRUvPTSSzaNyxYuL97HISkiIqK2aHNy8+CDD1rljQMDAyGTyVBQUGByvKCgACEhIWavCQ0NhZubG2QymfFYnz59kJ+fj7q6OigUimbXzJ8/HykpKcbfl5eXIyIiwiqfwZYM2y5wJ3AiIqK2aXPPzUcffYQvvvii2fEvvvgCn3zyicWvo1AoEB8fj7S0NOMxnU6HtLQ0JCYmmr1m+PDhyMzMhE6nMx47efIkQkNDzSY2AKBUKuHj42Py6OgatDocz2tc44bNxERERG3S5uQmNTUVgYGBzY4HBwfj1VdfbdNrpaSk4IMPPsAnn3yC48ePY86cOaiqqjLOnpoxYwbmz59vPH/OnDkoKSnBvHnzcPLkSWzYsAGvvvoq5s6d29aP0aGdLqqCpkEHT4UMUV08r34BERERGbV5WCo7OxvR0dHNjkdGRiI7O7tNrzVt2jQUFRVh4cKFyM/PR1xcHDZt2mRsMs7OzoZUejn/ioiIwI8//oinn34a1113HcLDwzFv3jz87W9/a+vH6NAM/TZ9w3wglbKZmIiIqC3anNwEBwfj0KFDzdaXOXjwILp06dLmAJKTk5GcnGz2ue3btzc7lpiYiN9//73N7+NM2G9DRETUfm0elrrvvvvw5JNPYtu2bdBqtdBqtdi6dSvmzZuHe++91xYxdjrGaeBcmZiIiKjN2ly5efnll3H27FmMHj0acrn+cp1OhxkzZrS554aa0+kEjl0wbJjJZmIiIqK2anNyo1AosHbtWvzf//0fDhw4AHd3dwwYMACRkZG2iK/TySquRKWmASo3KXoEeTk6HCIiIqfT7r2levXqhV69elkzFgKwP7sUADAg3BduMqvsjkFERNSptPnb86677sI//vGPZsdff/113H333VYJqjM7mFMKAIiL8HNoHERERM6qzcnNjh07cNtttzU7Pn78eOzYscMqQXVmB86XAgAGMrkhIiJqlzYnN5WVlWZXA3Zzc3OaTSk7qtp6LTLyKgCwckNERNRebU5uBgwYgLVr1zY7vmbNGvTt29cqQXVWR3LL0KATCPRSItzP3dHhEBEROaU2NxS/+OKLuPPOO3H69GnccsstAIC0tDSsXr0aX375pdUD7EwMQ1JxEX4mO68TERGR5dqc3EycOBHr16/Hq6++ii+//BLu7u4YOHAgtm7dioCAAFvE2GlcTm64eB8REVF7tWsq+IQJEzBhwgQAQHl5OT777DP85S9/wd69e6HVaq0aYGdyObnxd2wgRERETqzdC6ns2LEDM2fORFhYGN544w3ccsstLr/nky0VV2qQc6kGEglwHSs3RERE7damyk1+fj4+/vhjfPjhhygvL8c999wDjUaD9evXs5n4Gh1srNr0CPKCj8rNscEQERE5MYsrNxMnTkRMTAwOHTqEpUuX4sKFC3jnnXdsGVun0rSZmIiIiNrP4srNxo0b8eSTT2LOnDncdsEGuHgfERGRdVhcudm5cycqKioQHx+PhIQEvPvuuyguLrZlbJ2GTieMyc0gJjdERETXxOLk5vrrr8cHH3yAvLw8/PnPf8aaNWsQFhYGnU6HzZs3o6KiwpZxurQzF6tQUdsApVyKmBBvR4dDRETk1No8W8rT0xMPPfQQdu7cicOHD+OZZ57Ba6+9huDgYNxxxx22iNHlHeBO4ERERFZzTd+kMTExeP3115GTk4PPPvvMWjF1Ouy3ISIish6rlAlkMhkmT56Mb7/91hov1+lwphQREZH1cAzEwWrrtTiep99NnckNERHRtWNy42BHL5Q37gSuQFd/7gRORER0rZjcOJix36YrdwInIiKyBiY3DpZZWAkA6Bvm4+BIiIiIXAOTGwcrqqgFAIT4qhwcCRERkWtgcuNgBeUaAIDam8kNERGRNTC5cbCCcn3lRu3D5IaIiMgamNw4UINWh+LKxsqNj9LB0RAREbkGJjcOdLGqDjoBSCVAFy8mN0RERNbA5MaBDENSQd5KyKScBk5ERGQNTG4cqNDQTMx+GyIiIqthcuNABY3TwIO9OSRFRERkLUxuHMgwDTyYlRsiIiKrYXLjQIWGaeBc44aIiMhqOkRys2zZMkRFRUGlUiEhIQG7d+9u8dyPP/4YEonE5KFSOWdycHmNGw5LERERWYvDk5u1a9ciJSUFixYtwr59+zBw4ECMHTsWhYWFLV7j4+ODvLw84+PcuXN2jNh6CivYUExERGRtDk9ulixZgtmzZ2PWrFno27cvli9fDg8PD6xYsaLFayQSCUJCQowPtVptx4it53LPDSs3RERE1uLQ5Kaurg579+5FUlKS8ZhUKkVSUhLS09NbvK6yshKRkZGIiIjApEmTcPTo0RbP1Wg0KC8vN3l0BPVaHS5WNSY37LkhIiKyGocmN8XFxdBqtc0qL2q1Gvn5+WaviYmJwYoVK/DNN99g5cqV0Ol0uOGGG5CTk2P2/NTUVPj6+hofERERVv8c7VFcqYEQgEwqQRdPhaPDISIichkOH5Zqq8TERMyYMQNxcXEYOXIk1q1bh6CgIPznP/8xe/78+fNRVlZmfJw/f97OEZtnHJLyVkLK1YmJiIisRu7INw8MDIRMJkNBQYHJ8YKCAoSEhFj0Gm5ubhg0aBAyMzPNPq9UKqFUdryeFsM0cK5xQ0REZF0OrdwoFArEx8cjLS3NeEyn0yEtLQ2JiYkWvYZWq8Xhw4cRGhpqqzBtosAwU4qrExMREVmVQys3AJCSkoKZM2diyJAhGDZsGJYuXYqqqirMmjULADBjxgyEh4cjNTUVALB48WJcf/316NmzJ0pLS/HPf/4T586dwyOPPOLIj9FmxgX8WLkhIiKyKocnN9OmTUNRUREWLlyI/Px8xMXFYdOmTcYm4+zsbEillwtMly5dwuzZs5Gfnw9/f3/Ex8fjt99+Q9++fR31EdrFsIAf95UiIiKyLokQQjg6CHsqLy+Hr68vysrK4OPj47A4Zq7YjZ9PFuH1u67DPUM7xgwuIiKijqot399ON1vKVRhWJ+YCfkRERNbF5MZB2HNDRERkG0xuHKCuQYeLVXUAmNwQERFZG5MbByiq1A9Juckk8Pdwc3A0REREroXJjQNcnimlgkTC1YmJiIisicmNAxRyN3AiIiKbYXLjAIUVjc3E3A2ciIjI6pjcOECBcaYUKzdERETWxuTGAYw7gnOmFBERkdUxuXGAAq5xQ0REZDNMbhygyLA6MfeVIiIisjomNw7Ayg0REZHtMLmxM02DFpeq6wGwoZiIiMgWmNzYmWGNG4VcCl93rk5MRERkbUxu7My4xo2PkqsTExER2QCTGzszTAPnAn5ERES2weTGzgoN+0qx34aIiMgmmNzYWYFxGjgrN0RERLbA5MbOOA2ciIjItpjc2JlhthSngRMREdkGkxs7Y+WGiIjItpjc2FlhBSs3REREtsTkxo5q67Uoq9GvThzEhmIiIiKbYHJjR4YNMxVyKXxUcgdHQ0RE5JqY3NiRoWrj7+HG1YmJiIhshMmNHRmSG+4pRUREZDtMbuyotHE3cD93hYMjISIicl1MbuzIULnxYeWGiIjIZpjc2FFpTR0AwM+DyQ0REZGtMLmxI/bcEBER2R6TGzsqM/bcMLkhIiKyFSY3dmSs3HBYioiIyGaY3NiRYbYUh6WIiIhsp0MkN8uWLUNUVBRUKhUSEhKwe/dui65bs2YNJBIJJk+ebNsArYQ9N0RERLbn8ORm7dq1SElJwaJFi7Bv3z4MHDgQY8eORWFhYavXnT17Fn/5y19w44032inSa2dIbvw8uM4NERGRrTg8uVmyZAlmz56NWbNmoW/fvli+fDk8PDywYsWKFq/RarWYPn06XnrpJXTv3t2O0V4bVm6IiIhsz6HJTV1dHfbu3YukpCTjMalUiqSkJKSnp7d43eLFixEcHIyHH374qu+h0WhQXl5u8nCEeq0OlZoGAJwtRUREZEsOTW6Ki4uh1WqhVqtNjqvVauTn55u9ZufOnfjwww/xwQcfWPQeqamp8PX1NT4iIiKuOe72KG+s2gBcoZiIiMiWHD4s1RYVFRV44IEH8MEHHyAwMNCia+bPn4+ysjLj4/z58zaO0rzSxuTGWyWHTModwYmIiGxF7sg3DwwMhEwmQ0FBgcnxgoIChISENDv/9OnTOHv2LCZOnGg8ptPpAAByuRwnTpxAjx49TK5RKpVQKpU2iL5t2G9DRERkHw6t3CgUCsTHxyMtLc14TKfTIS0tDYmJic3Oj42NxeHDh3HgwAHj44477sDNN9+MAwcOOGzIyRLG1Ym5gB8REZFNObRyAwApKSmYOXMmhgwZgmHDhmHp0qWoqqrCrFmzAAAzZsxAeHg4UlNToVKp0L9/f5Pr/fz8AKDZ8Y6GlRsiIiL7cHhyM23aNBQVFWHhwoXIz89HXFwcNm3aZGwyzs7OhlTqVK1BZpVWN+4I7s41boiIiGzJ4ckNACQnJyM5Odnsc9u3b2/12o8//tj6AdlAWY1+GjhnShEREdmW85dEnERpTWPlhj03RERENsXkxk7Yc0NERGQfTG7sxDhbiskNERGRTTG5sRNWboiIiOyDyY2dGFYo9mXPDRERkU0xubETVm6IiIjsg8mNHQghmqxQzHVuiIiIbInJjR3U1utQp9XvgcXKDRERkW0xubEDwxo3cqkEngqZg6MhIiJybUxu7KBpv41EInFwNERERK6NyY0dlFZzphQREZG9MLmxA86UIiIish8mN3bA1YmJiIjsh8mNHbByQ0REZD9Mbuzg8o7gXOOGiIjI1pjc2IGhodiHlRsiIiKbY3JjB4ZhKfbcEBER2R6TGztgzw0REZH9MLmxA2PlhuvcEBER2RyTGzswLuLHyg0REZHNMbmxA1ZuiIiI7IfJjY3pdALltZwtRUREZC9MbmysorYBQuh/zWEpIiIi22NyY2OGBfzc3WRQymUOjoaIiMj1MbmxMfbbEBER2ReTGxvjTCkiIiL7YnJjY1zAj4iIyL6Y3NhYKZMbIiIiu2JyY2Pl7LkhIiKyKyY3NlZarZ8txcoNERGRfTC5sbHLs6UUDo6EiIioc2ByY2OG2VJcnZiIiMg+mNzYmLFyw+SGiIjILjpEcrNs2TJERUVBpVIhISEBu3fvbvHcdevWYciQIfDz84Onpyfi4uLw6aef2jHatuFUcCIiIvtyeHKzdu1apKSkYNGiRdi3bx8GDhyIsWPHorCw0Oz5AQEBWLBgAdLT03Ho0CHMmjULs2bNwo8//mjnyC3DFYqJiIjsy+HJzZIlSzB79mzMmjULffv2xfLly+Hh4YEVK1aYPX/UqFGYMmUK+vTpgx49emDevHm47rrrsHPnTjtHbhmuUExERGRfDk1u6urqsHfvXiQlJRmPSaVSJCUlIT09/arXCyGQlpaGEydO4KabbjJ7jkajQXl5ucnDXjQNWtTUawEAfu6cLUVERGQPDk1uiouLodVqoVarTY6r1Wrk5+e3eF1ZWRm8vLygUCgwYcIEvPPOOxgzZozZc1NTU+Hr62t8REREWPUztMYwJCWRAN4qud3el4iIqDNz+LBUe3h7e+PAgQPYs2cPXnnlFaSkpGD79u1mz50/fz7KysqMj/Pnz9stTsPqxD4qN0ilEru9LxERUWfm0HJCYGAgZDIZCgoKTI4XFBQgJCSkxeukUil69uwJAIiLi8Px48eRmpqKUaNGNTtXqVRCqVRaNW5Lsd+GiIjI/hxauVEoFIiPj0daWprxmE6nQ1paGhITEy1+HZ1OB41GY4sQrwlnShEREdmfwxtBUlJSMHPmTAwZMgTDhg3D0qVLUVVVhVmzZgEAZsyYgfDwcKSmpgLQ99AMGTIEPXr0gEajwQ8//IBPP/0U7733niM/hlms3BAREdmfw5ObadOmoaioCAsXLkR+fj7i4uKwadMmY5NxdnY2pNLLBaaqqio8/vjjyMnJgbu7O2JjY7Fy5UpMmzbNUR+hRVzAj4iIyP4kQgjh6CDsqby8HL6+vigrK4OPj49N32vJ5pN4O+0Upid0wytTBtj0vYiIiFxZW76/nXK2lLMoZ88NERGR3TG5saFL1XUAOCxFRERkT0xubOjYBf1qyJFdPB0cCRERUefB5MZGSqrqcKqwEgAwNCrAwdEQERF1HkxubGTP2RIAQK9gLwR4cl8pIiIie2FyYyN7zuiTm6HRrNoQERHZE5MbG9ndWLkZxiEpIiIiu2JyYwOVmgYcbWwmHsbKDRERkV0xubGBfecuQasTCPdzR5ifu6PDISIi6lSY3NiAoZk4gVUbIiIiu2NyYwO72UxMRETkMExurEzToMX+86UAuL4NERGRIzC5sbLDOWWoa9Chi6cCPYK4MjEREZG9Mbmxsl2GIamoAEgkEgdHQ0RE1PkwubEyQzMxp4ATERE5BpMbK9LqBPaevQSAyQ0REZGjMLmxouN55ajQNMBLKUefUB9Hh0NERNQpMbmxIsOQVHykP2RS9tsQERE5ApMbKzKsb8MhKSIiIsdhcmMlQgg2ExMREXUATG6sJKu4CsWVdVDIpbiuq6+jwyEiIuq05I4OwFXkldY2LtznBaVc5uhwiIiIOi0mN1Yyolcg/nghCWU19Y4OhYiIqFPjsJQVSSQS+HkoHB0GERFRp8bkhoiIiFwKkxsiIiJyKUxuiIiIyKUwuSEiIiKXwuSGiIiIXAqTGyIiInIpTG6IiIjIpTC5ISIiIpfC5IaIiIhcSodIbpYtW4aoqCioVCokJCRg9+7dLZ77wQcf4MYbb4S/vz/8/f2RlJTU6vlERETUuTg8uVm7di1SUlKwaNEi7Nu3DwMHDsTYsWNRWFho9vzt27fjvvvuw7Zt25Ceno6IiAjceuutyM3NtXPkRERE1BFJhBDCkQEkJCRg6NChePfddwEAOp0OEREReOKJJ/Dcc89d9XqtVgt/f3+8++67mDFjxlXPLy8vh6+vL8rKyuDj43PN8RMREZHtteX726GVm7q6OuzduxdJSUnGY1KpFElJSUhPT7foNaqrq1FfX4+AgACzz2s0GpSXl5s8iIiIyHXJHfnmxcXF0Gq1UKvVJsfVajUyMjIseo2//e1vCAsLM0mQmkpNTcVLL73U7DiTHCIiIudh+N62ZMDJocnNtXrttdewZs0abN++HSqVyuw58+fPR0pKivH3ubm56Nu3LyIiIuwVJhEREVlJRUUFfH19Wz3HoclNYGAgZDIZCgoKTI4XFBQgJCSk1Wv/9a9/4bXXXsOWLVtw3XXXtXieUqmEUqk0/t7Lywvnz5+Ht7c3JBLJtX2AK5SXlyMiIgLnz59nP4+N8V7bD++1/fBe2w/vtf1Y614LIVBRUYGwsLCrnuvQ5EahUCA+Ph5paWmYPHkyAH1DcVpaGpKTk1u87vXXX8crr7yCH3/8EUOGDGnTe0qlUnTt2vVawr4qHx8f/s9iJ7zX9sN7bT+81/bDe20/1rjXV6vYGDh8WColJQUzZ87EkCFDMGzYMCxduhRVVVWYNWsWAGDGjBkIDw9HamoqAOAf//gHFi5ciNWrVyMqKgr5+fkA9BUZLy8vh30OIiIi6hgcntxMmzYNRUVFWLhwIfLz8xEXF4dNmzYZm4yzs7MhlV6e1PXee++hrq4OU6dONXmdRYsW4e9//7s9QyciIqIOyOHJDQAkJye3OAy1fft2k9+fPXvW9gG1k1KpxKJFi0x6fMg2eK/th/fafniv7Yf32n4cca8dvogfERERkTU5fPsFIiIiImtickNEREQuhckNERERuRQmN0RERORSmNxYybJlyxAVFQWVSoWEhATs3r3b0SE5vdTUVAwdOhTe3t4IDg7G5MmTceLECZNzamtrMXfuXHTp0gVeXl646667mq14TW332muvQSKR4KmnnjIe4722ntzcXNx///3o0qUL3N3dMWDAAPzxxx/G54UQWLhwIUJDQ+Hu7o6kpCScOnXKgRE7J61WixdffBHR0dFwd3dHjx498PLLL5vsTcR73X47duzAxIkTERYWBolEgvXr15s8b8m9LSkpwfTp0+Hj4wM/Pz88/PDDqKysvPbgBF2zNWvWCIVCIVasWCGOHj0qZs+eLfz8/ERBQYGjQ3NqY8eOFR999JE4cuSIOHDggLjttttEt27dRGVlpfGcxx57TERERIi0tDTxxx9/iOuvv17ccMMNDoza+e3evVtERUWJ6667TsybN894nPfaOkpKSkRkZKR48MEHxa5du0RWVpb48ccfRWZmpvGc1157Tfj6+or169eLgwcPijvuuENER0eLmpoaB0bufF555RXRpUsX8f3334szZ86IL774Qnh5eYm33nrLeA7vdfv98MMPYsGCBWLdunUCgPj6669Nnrfk3o4bN04MHDhQ/P777+KXX34RPXv2FPfdd981x8bkxgqGDRsm5s6da/y9VqsVYWFhIjU11YFRuZ7CwkIBQPz8889CCCFKS0uFm5ub+OKLL4znHD9+XAAQ6enpjgrTqVVUVIhevXqJzZs3i5EjRxqTG95r6/nb3/4mRowY0eLzOp1OhISEiH/+85/GY6WlpUKpVIrPPvvMHiG6jAkTJoiHHnrI5Nidd94ppk+fLoTgvbamK5MbS+7tsWPHBACxZ88e4zkbN24UEolE5ObmXlM8HJa6RnV1ddi7dy+SkpKMx6RSKZKSkpCenu7AyFxPWVkZACAgIAAAsHfvXtTX15vc+9jYWHTr1o33vp3mzp2LCRMmmNxTgPfamr799lsMGTIEd999N4KDgzFo0CB88MEHxufPnDmD/Px8k3vt6+uLhIQE3us2uuGGG5CWloaTJ08CAA4ePIidO3di/PjxAHivbcmSe5ueng4/Pz+TPSKTkpIglUqxa9eua3r/DrFCsTMrLi6GVqs1bhdhoFarkZGR4aCoXI9Op8NTTz2F4cOHo3///gCA/Px8KBQK+Pn5mZyrVquNe46R5dasWYN9+/Zhz549zZ7jvbaerKwsvPfee0hJScHzzz+PPXv24Mknn4RCocDMmTON99Pc3ym8123z3HPPoby8HLGxsZDJZNBqtXjllVcwffp0AOC9tiFL7m1+fj6Cg4NNnpfL5QgICLjm+8/khpzC3LlzceTIEezcudPRobik8+fPY968edi8eTNUKpWjw3FpOp0OQ4YMwauvvgoAGDRoEI4cOYLly5dj5syZDo7OtXz++edYtWoVVq9ejX79+uHAgQN46qmnEBYWxnvt4jgsdY0CAwMhk8mazRopKChASEiIg6JyLcnJyfj++++xbds2dO3a1Xg8JCQEdXV1KC0tNTmf977t9u7di8LCQgwePBhyuRxyuRw///wz3n77bcjlcqjVat5rKwkNDUXfvn1NjvXp0wfZ2dkAYLyf/Dvl2j377LN47rnncO+992LAgAF44IEH8PTTTyM1NRUA77UtWXJvQ0JCUFhYaPJ8Q0MDSkpKrvn+M7m5RgqFAvHx8UhLSzMe0+l0SEtLQ2JiogMjc35CCCQnJ+Prr7/G1q1bER0dbfJ8fHw83NzcTO79iRMnkJ2dzXvfRqNHj8bhw4dx4MAB42PIkCGYPn268de819YxfPjwZksanDx5EpGRkQCA6OhohISEmNzr8vJy7Nq1i/e6jaqrqyGVmn7NyWQy6HQ6ALzXtmTJvU1MTERpaSn27t1rPGfr1q3Q6XRISEi4tgCuqR2ZhBD6qeBKpVJ8/PHH4tixY+LRRx8Vfn5+Ij8/39GhObU5c+YIX19fsX37dpGXl2d8VFdXG8957LHHRLdu3cTWrVvFH3/8IRITE0ViYqIDo3YdTWdLCcF7bS27d+8WcrlcvPLKK+LUqVNi1apVwsPDQ6xcudJ4zmuvvSb8/PzEN998Iw4dOiQmTZrE6cntMHPmTBEeHm6cCr5u3ToRGBgo/vrXvxrP4b1uv4qKCrF//36xf/9+AUAsWbJE7N+/X5w7d04IYdm9HTdunBg0aJDYtWuX2Llzp+jVqxengnck77zzjujWrZtQKBRi2LBh4vfff3d0SE4PgNnHRx99ZDynpqZGPP7448Lf3194eHiIKVOmiLy8PMcF7UKuTG54r63nu+++E/379xdKpVLExsaK999/3+R5nU4nXnzxRaFWq4VSqRSjR48WJ06ccFC0zqu8vFzMmzdPdOvWTahUKtG9e3exYMECodFojOfwXrfftm3bzP4dPXPmTCGEZff24sWL4r777hNeXl7Cx8dHzJo1S1RUVFxzbBIhmizVSEREROTk2HNDRERELoXJDREREbkUJjdERETkUpjcEBERkUthckNEREQuhckNERERuRQmN0RERORSmNwQUacnkUiwfv16R4dBRFbC5IaIHOrBBx+ERCJp9hg3bpyjQyMiJyV3dABEROPGjcNHH31kckypVDooGiJydqzcEJHDKZVKhISEmDz8/f0B6IeM3nvvPYwfPx7u7u7o3r07vvzyS5PrDx8+jFtuuQXu7u7o0qULHn30UVRWVpqcs2LFCvTr1w9KpRKhoaFITk42eb64uBhTpkyBh4cHevXqhW+//da2H5qIbIbJDRF1eC+++CLuuusuHDx4ENOnT8e9996L48ePAwCqqqowduxY+Pv7Y8+ePfjiiy+wZcsWk+Tlvffew9y5c/Hoo4/i8OHD+Pbbb9GzZ0+T93jppZdwzz334NChQ7jtttswffp0lJSU2PVzEpGVXPPWm0RE12DmzJlCJpMJT09Pk8crr7wihNDvDv/YY4+ZXJOQkCDmzJkjhBDi/fffF/7+/qKystL4/IYNG4RUKhX5+flCCCHCwsLEggULWowBgHjhhReMv6+srBQAxMaNG632OYnIfthzQ0QOd/PNN+O9994zORYQEGD8dWJioslziYmJOHDgAADg+PHjGDhwIDw9PY3PDx8+HDqdDidOnIBEIsGFCxcwevToVmO47rrrjL/29PSEj48PCgsL2/uRiMiBmNwQkcN5eno2GyayFnd3d4vOc3NzM/m9RCKBTqezRUhEZGPsuSGiDu/3339v9vs+ffoAAPr06YODBw+iqqrK+Pyvv/4KqVSKmJgYeHt7IyoqCmlpaXaNmYgch5UbInI4jUaD/Px8k2NyuRyBgYEAgC+++AJDhgzBiBEjsGrVKuzevRsffvghAGD69OlYtGgRZs6cib///e8oKirCE088gQceeABqtRoA8Pe//x2PPfYYgoODMX78eFRUVODXX3/FE088Yd8PSkR2weSGiBxu06ZNCA0NNTkWExODjIwMAPqZTGvWrMHjjz+O0NBQfPbZZ+jbty8AwMPDAz/++CPmzZuHoUOHwsPDA3fddReWLFlifK2ZM2eitrYWb775Jv7yl78gMDAQU6dOtd8HJCK7kgghhKODICJqiUQiwddff43Jkyc7OhQichLsuSEiIiKXwuSGiIiIXAp7boioQ+PIORG1FSs3RERE5FKY3BAREZFLYXJDRERELoXJDREREbkUJjdERETkUpjcEBERkUthckNEREQuhckNERERuRQmN0RERORS/h+8UEdLGrNMUAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'],color ='tab:blue')\n",
        "plt.title('Accuracy Vs Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "plt.savefig('Accuracy_Vs_Epoch.png',dpi=300)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'],color ='tab:red')\n",
        "plt.title('Loss Vs Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "plt.savefig('Loss_Vs_Epoch.png',dpi=300)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNdgz1uANT3KBSHnT9uHYeW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}